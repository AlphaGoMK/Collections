# Object Detection

## AutoAssign: Differentiable Label Assignment for Dense Object Detection

> Label-assignment, é€‰æ‹©æ­£/è´Ÿæ ·æœ¬ç‚¹(anchor-free)éœ€è¦åŠ¨æ€ç¡®å®šï¼Œä¸”æ­£è´Ÿæ ·æœ¬ç‚¹æŸå¤±åŠ æƒã€‚æƒé‡ï¼šcate+ç‰©ä½“è®¡ç®—
>
> center prior: è®­ç»ƒæ—¶å›ºå®šå…ˆéªŒ
>
> (instance) confidence map: æ ¹æ®æ•°æ®åŠ¨æ€è°ƒæ•´

ä¹‹å‰ç©ºé—´ä¸Šé‡‡æ ·æ­£è´Ÿæ ·æœ¬çš„æ–¹æ³•ä¸º 1. IoU 2. ç‰©ä½“æ¡†ä¸­å¿ƒå›ºå®šåŒºåŸŸéƒ½ä¸ºæ­£æ ·æœ¬ã€‚ä½†å­˜åœ¨ç‰©ä½“æ¡†ä¸­éƒ¨åˆ†åŒºåŸŸæ²¡æœ‰ç‰©ä½“ï¼Œä¸”å›ºå®šåŒºåŸŸæ— æ³•ä¼˜åŒ– *obstacle caused by feature shifting when backgrounds are sampled as positives may decrease the performance.*

æå‡ºæ ¹æ®category&instanceä¿¡æ¯åŠ¨æ€äº§ç”Ÿpos/neg weight map [**differentiable/data-driven**]

![image-20200715142809070](Figures/image-20200715142809070.png)

![image-20200715142902639](Figures/image-20200715142902639.png)

ğŸ‘†æ›´åŠ dynamic

![image-20200715143039412](Figures/image-20200715143039412.png)

é€šè¿‡Center Weighting + Confidence Weightingå¾—åˆ°Weight Map($w^+,w^-$)

#### Center Weighting

å­¦ä¹ ä¸€ä¸ªcategory-wiseåˆ†å¸ƒï¼Œå³å¸¦å‚æ•°çš„Gaussian-shape weighting functionï¼Œç”¨åœ¨FPNçš„æ¯ä¸€å±‚ã€‚

$G(\vec{d} \mid \vec{\mu}, \vec{\sigma})=e^{\frac{-(\vec{d}-\vec{\mu})^{2}}{2 \vec{\sigma}^{2}}}$ï¼Œå…¶ä¸­$\vec{d}$ä¸ºæŸä¸ªä½ç½®çš„xyåç§»é‡ï¼Œä¸€ç§ç±»åˆ«æœ‰ä¸€ç»„$\vec{\mu}\;\vec{\sigma}$

center priorå¯ä»¥<u>å¢åŠ ç±»åˆ«çš„å…ˆéªŒåˆ†å¸ƒä¿¡æ¯</u>ï¼Œé˜²æ­¢ç½‘ç»œå†·å¯åŠ¨åå‡ºç°è¿‡æ‹Ÿåˆï¼ˆä¸æ–­ä¼˜åŒ–ç¬¬ä¸€æ¬¡wé«˜çš„ç‚¹ï¼‰

ç”±äºconf weightingä½œç”¨çš„æ˜¯<u>æ¯ä¸ªGT-Boxä¸­æ‰€æœ‰ç‚¹</u>ï¼Œæ‰€ä»¥åº”ç”¨center prioræ—¶å·²çŸ¥ç±»åˆ«

#### Confidence Weighting

![æˆªå±2020-07-15 ä¸‹åˆ3.02.53](Figures/%E6%88%AA%E5%B1%8F2020-07-15%20%E4%B8%8B%E5%8D%883.02.53-4796696.png)

å¢åŠ Implicit-Objectnessåˆ†æ”¯ï¼ŒæŠ‘åˆ¶false-posï¼ˆæ¡†å†…éƒ¨åˆ†ç‚¹ä¸åœ¨ç‰©ä½“ä¸Šï¼‰

è®­ç»ƒæ—¶åˆ†ç±»åˆ†æ”¯ä¸€èµ·è®­ç»ƒ $\mathcal{P}_{i}(\operatorname{cls}\mid\theta)=\mathcal{P}_{i}(\operatorname{cls}\mid obj, \theta) \mathcal{P}_{i}(\text {obj} \mid \theta)$

è®¤ä¸ºä¹‹å‰å›ºå®šåŒ¹é…æ¨¡å‹çš„åˆ†ç±»åˆ†æ”¯ä¸º<u>å·²çŸ¥ç‚¹æ˜¯æ­£æ ·æœ¬</u>$\mathcal{P}_i(obj\mid\theta)=1$ï¼Œé¢„æµ‹ç‚¹ä¸ºæŸä¸ªç±»åˆ«çš„æ¦‚ç‡ï¼Œå³åˆ†ç±»åˆ†æ”¯çš„ç»“æœä¸ºæ˜¯$\mathcal{P}_i(cls|obj,\theta)$æ¡ä»¶æ¦‚ç‡ã€‚$\mathcal{P}_i(cls\mid\theta)=\mathcal{P}_i(cls\mid obj,\theta)$, $\theta$æ˜¯å‚æ•°

ç°åœ¨æ”¹ä¸ºImpl-Objåˆ†æ”¯é¢„æµ‹$\mathcal{P}_i(obj\mid\theta)$ï¼Œå†å’Œåˆ†ç±»åˆ†æ”¯$\mathcal{P}_{i}(cls\mid obj, \theta)$ä¸€èµ·å¾—åˆ°$\mathcal{P}_i(cls\mid\theta)$

ä¸”å¢åŠ localization confä½œä¸ºè®¡ç®—æ ·æœ¬æƒé‡çš„ä¾æ®ï¼Œé€šè¿‡æŒ‡æ•°å‡½æ•°å°†å®šä½å‡†ç¡®ç‡è½¬ä¸ºlikelihood$\mathcal{P}_i(\theta)=\mathcal{P}_i(cls\mid\theta)\mathcal{e}^{-\lambda\mathcal{L}_i^{loc}(\theta)}$ï¼Œåœ¨è®¡ç®—lossä½“ç°ã€‚ç±»ä¼¼*Learning From Noisy Anchors for One-Stage Object Detection* ç»¼åˆè€ƒè™‘åˆ†ç±»å’Œå®šä½çš„æ€§èƒ½

$\begin{aligned} \mathcal{L}_{i}(\theta) &=\mathcal{L}_{i}^{c l s}(\theta)+\lambda \mathcal{L}_{i}^{l o c}(\theta) \\ &=-\log \left(\mathcal{P}_{i}(c l s \mid \theta)\right)+\lambda \mathcal{L}_{i}^{l o c}(\theta) \\ &=-\log \left(\mathcal{P}_{i}(c l s \mid \theta) e^{-\lambda \mathcal{L}_{i}^{l o c}(\theta)}\right) \\ &=-\log \left(\mathcal{P}_{i}(c l s \mid \theta) \mathcal{P}_{i}(loc \mid \theta)\right) \\ &=-\log \left(\mathcal{P}_{i}(\theta)\right) \end{aligned}$

joint conf representation $\mathcal{P}_i(\theta)$ç»è¿‡æŒ‡æ•°è®¡ç®—ï¼Œå¢å¼º$C\left(\mathcal{P}_{i}\right)=e^{\frac{\mathcal{P}_{i}(\theta)}{\tau}}$ ï¼ˆåªä¼šæœ‰ä¸€å°éƒ¨åˆ†è½åœ¨ç‰©ä½“ä¸Šï¼Œå¾—åˆ†é«˜ï¼‰

#### Weight Map

å¯¹ä¸€ä¸ª**GTæ¡†å†…çš„ç‚¹**è®¡ç®—æƒé‡ï¼Œfocus on proper loc inside bbox

èåˆï¼Œæ±‚æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬æƒé‡

$w_{i}^{+}=\frac{C\left(\mathcal{P}_{i}\right) G\left(\vec{d}_{i}\right)}{\sum_{j \in S_{n}} C\left(\mathcal{P}_{i}\right) G\left(\vec{d}_{i}\right)}$

$w_{i}^{-}=1-f\left(\frac{1}{1-\mathrm{i} \mathrm{ou}_{i}}\right)$ï¼Œf normalize to [0,1]ï¼Œ<u>åˆ†æ•°ä¸ºsharpenæƒé‡åˆ†å¸ƒ</u>

Losså‡½æ•°$\mathcal{L}(\theta)=-\sum_{n=1}^{N} \log \left(\sum_{i \in S_{n}} w_{i}^{+} \mathcal{P}_{i}^{+}\right)-\sum_{j \in S} \log \left(w_{j}^{-} \mathcal{P}_{j}^{-}\right)$

ğŸ‘†å­¦ä¹ ç­–ç•¥ä¸ºä¸€ä¸ªboxçš„è®­ç»ƒï¼Œå¯¹ä¸€ä¸ªboxæ„å»º$w^+/w^-$è®­ç»ƒ

ä¸åŒå°ºåº¦çƒ­åŠ›å›¾å¯è§†åŒ–ğŸ‘‡

![image-20200715150853109](Figures/image-20200715150853109.png)

ğŸ‘‡ImplicitObjectnessæŠ‘åˆ¶å™ªå£°æ•ˆæœæ˜¾è‘—

![image-20200807112856084](Figures/image-20200807112856084.png)

åŸºäºFCOSï¼Œæå‡2-3ç‚¹ï¼ŒmAP=52.1%

---

## Towards Accurate One-Stage Object Detection with AP-Loss

> Label-assignment

æ­£è´Ÿæ ·æœ¬ä¸å‡è¡¡é—®é¢˜ *It is observed that the classification metric could be very high for a trivial solution which predicts negative label for almost all candidate boxes, while the detection performance is poor*

<img src="Figures/image-20200716164022633.png" alt="image-20200716164022633" style="zoom:50%;" />

è´Ÿæ ·æœ¬å¤šï¼Œæ­£æ ·æœ¬åˆ†ç±»ç»“æœå¯¹lossè´¡çŒ®å°‘ï¼Œå¯¹æ£€æµ‹accå½±å“å°

æå‡ºç›´æ¥å¯¹AP(average precision)ä¼˜åŒ–ï¼šAP Loss

<u>æŠŠåˆ†ç±»åˆ†æ”¯é—®é¢˜çœ‹ä¸ºä¸€ä¸ªranké—®é¢˜ï¼Œè®¡ç®—AP Lossï¼Œé‡‡ç”¨error-drivenæ–¹å¼ä¼˜åŒ–</u>

#### Ranking Task & AP Loss

å› ä¸ºè®¡ç®—APè¿‡ç¨‹å®é™…æ˜¯å¯¹é¢„æµ‹ç»“æœæ’åºï¼Œå†è®¡ç®—ï¼Œæ‰€ä»¥æŠŠåˆ†ç±»é—®é¢˜çœ‹ä½œä¸€ä¸ªrankingé—®é¢˜ï¼šå¯¹äºæ¯ä¸€ç±»ï¼Œæ‰€æœ‰çš„æ­£æ ·æœ¬ç‚¹æ’åœ¨è´Ÿæ ·æœ¬ç‚¹ä¹‹å‰ï¼ˆæ›´é«˜åˆ†ï¼‰

AP-Lossçš„primary termä¸ºï¼š$(3)\;\;L_{i j}(\boldsymbol{x})=\frac{H\left(x_{i j}\right)}{1+\sum_{k \in \mathcal{P} \cup \mathcal{N}, k \neq i} H\left(x_{i k}\right)}=L_{i j}$ . å…¶ä¸­$x_{ij}$ä¸ºä¸¤ç‚¹çš„æ’åºå·®è·ï¼š$\forall i, j, \quad x_{i j}=-\left(s_{i}-s_{j}\right)$å°†åˆ†ç±»é¢„æµ‹çš„åˆ†æ•°è½¬åŒ–ä¸ºæ’åºxï¼Œä½œä¸ºæŸå¤±å‡½æ•°çš„è¾“å…¥ï¼ŒHä¸ºHeaviside step functioné˜¶è·ƒå‡½æ•°ï¼š$H(x)=\left\{\begin{array}{ll}0 & x<0 \\ 1 & x \geq 0\end{array}\right.$

å³åªæœ‰jæ’åœ¨iä¹‹å‰æ—¶ï¼Œæ‰å¯¹$L_{ij}$æœ‰è´¡çŒ®ã€‚GTå®šä¹‰ä¸º$\forall i, j, \quad y_{i j}=\mathbf{1}_{t_{i}=1, t_{j}=0}$

AP-Lossä¸ºï¼š

$\mathcal{L}_{A P}=1-\mathrm{AP}=1-\frac{1}{|\mathcal{P}|} \sum_{i \in \mathcal{P}} \frac{\operatorname{rank}^{+}(i)}{\operatorname{rank}(i)}$ 
$=1-\frac{1}{|\mathcal{P}|} \sum_{i \in \mathcal{P}} \frac{1+\sum_{j \in \mathcal{P}, j \neq i} H\left(x_{i j}\right)}{1+\sum_{j \in \mathcal{P}, j \neq i} H\left(x_{i j}\right)+\sum_{j \in \mathcal{N}} H\left(x_{i j}\right)}=\frac{1}{\mathcal{P}}\left(\mathcal{P}-\sum_{i \in \mathcal{P}} \frac{1+\sum_{j \in \mathcal{P}, j \neq i} H\left(x_{i j}\right)}{1+\sum_{j \in \mathcal{P}, j \neq i} H\left(x_{i j}\right)+\sum_{j \in \mathcal{N}} H\left(x_{i j}\right)}\right)=\frac{1}{\mathcal{P}}\sum_{i\in\mathcal{P}}\frac{\sum_{j\in\mathcal{N}}H(x_{ij})}{1+\sum_{j\in\mathcal{P},j\neq i}H(x_{ij})+\sum_{j\in\mathcal{N}}H(x_{ij})}$

$=\frac{1}{|\mathcal{P}|} \sum_{i \in \mathcal{P}} \sum_{j \in \mathcal{N}} L_{i j}=\frac{1}{|\mathcal{P}|} \sum_{i, j} L_{i j} \cdot y_{i j}=\frac{1}{|\mathcal{P}|}\langle\boldsymbol{L}(\boldsymbol{x}), \boldsymbol{y}\rangle$ ï¼ˆç”±äºåªæœ‰i jåˆ†å±æ­£è´Ÿæ—¶$L_{ij}$é0ï¼ŒåŒ$y$çš„å®šä¹‰ï¼‰

å³ä¸ºè®¡ç®—ä»»æ„ä¸€ä¸ªæ­£æ ·æœ¬På’Œä¸€ä¸ªè´Ÿæ ·æœ¬Nçš„primary termã€‚æ­£æ ·æœ¬ä¹‹é—´æ²¡æœ‰ï¼Œæ­£è´Ÿæ ·æœ¬ä¹‹é—´æœ‰æŸå¤±

$\min _{\boldsymbol{\theta}} \mathcal{L}_{A P}(\boldsymbol{\theta})=1-\operatorname{AP}(\boldsymbol{\theta})=\frac{1}{|\mathcal{P}|}\langle\boldsymbol{L}(\boldsymbol{x}(\boldsymbol{\theta})), \boldsymbol{y}\rangle$

#### Error-driven Update

*the update is directly derived from the difference between desired output and current output*ï¼š$\Delta x_{i j}=L^*_{i,j}-L_{i j}$

æœ€å°åŒ–AP-Lossåˆ°0ï¼Œå³æœ€ä½³ä¼˜åŒ–æ–¹å‘$\Delta x_{i j}=-L_{i j} \cdot y_{i j}$ï¼Œyæ§åˆ¶æ˜¯å¦å¯¹äºlossæœ‰è´¡çŒ®

ä¼˜åŒ–æ—¶ï¼Œè¡¡é‡æ”¹å˜å‚æ•°$\theta$åxçš„å˜åŒ–ä¸æœ€ä½³ä¼˜åŒ–æ–¹å‘ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œä»¥åŠL2æ­£åˆ™

$\arg \min _{\Delta \boldsymbol{\theta}}\left\{-\left\langle\Delta \boldsymbol{x}, \boldsymbol{x}\left(\boldsymbol{\theta}^{(n)}+\Delta \boldsymbol{\theta}\right)-\boldsymbol{x}\left(\boldsymbol{\theta}^{(n)}\right)\right\rangle+\lambda\|\Delta \boldsymbol{\theta}\|_{2}^{2}\right\}$ï¼Œä¸€é˜¶æ³°å‹’å±•å¼€ç®—å‚æ•°çš„ä¼˜åŒ–æ–¹å‘

ç”±äºå‚æ•°å˜åŒ–$\mathcal{\theta}^{(n+1)}-\mathcal{\theta}^{(n)}$åœ¨BPè¿‡ç¨‹ä¸­ä¸å˜ï¼Œæ‰€ä»¥æœ€ä½³ä¼˜åŒ–æ–¹å‘$\Delta x_{ij}$å³ä¸ºxçš„æ¢¯åº¦ï¼Œé“¾å¼æ±‚sçš„æ¢¯åº¦

$(13)\;\;\begin{aligned} g_{i}&=-\sum_{j, k} \Delta x_{j k} \cdot \frac{\partial x_{j k}}{\partial s_{i}}=\sum_{j} \Delta x_{i j}-\sum_{j} \Delta x_{j i} \\ &=\sum_{j} L_{j i} \cdot y_{j i}-\sum_{j} L_{i j} \cdot y_{i j} \end{aligned}$

<img src="Figures/image-20200716173631622.png" alt="image-20200716173631622" style="zoom:50%;" />

æ€§èƒ½åŸºäºRetinaNetæå‡3ä¸ªç‚¹

---

## DR Loss: Improving Object Detection by Distributional Ranking

> åŸºäºAP-Lossï¼Œé‡‡ç”¨ç±»ä¼¼SVMæ–¹å¼å¯¹æ­£è´Ÿæ ·æœ¬æ’åºï¼ˆmarginï¼‰
>
> å¢åŠ å¯¹æ­£è´Ÿæ ·æœ¬åˆ†å¸ƒçš„æ”¹å˜ reweight

<img src="Figures/image-20200716173939029.png" alt="image-20200716173939029" style="zoom:50%;" />

## Scale-Equalizing Pyramid Convolution for Object Detection (SEPC)

>é‡‡ç”¨3Då·ç§¯è¿›è¡Œå¤šå°ºåº¦ç‰¹å¾èåˆï¼Œä¸åŒå±‚èåˆæƒé‡ä¸åŒ

ç‰¹å¾é‡‘å­—å¡”ä¸åŒå±‚ä¹‹é—´å­˜åœ¨semantic gapï¼Œä¹‹å‰é‡‡ç”¨feature fusionè§£å†³ä½†æ²¡æœ‰æå–intrinsic property

**Pyramid Conv** `PConv`: **åœ¨å°ºåº¦ç»´ä¸Š (ä¸åŒå±‚ç‰¹å¾å›¾)** åšå·ç§¯ï¼ˆlike spatial convï¼‰ï¼Œ3D conv

é€‰æ‹©ä¸‰å±‚ï¼Œåº•å±‚é‡‡ç”¨strideå·ç§¯ï¼Œä¸­é—´æ™®é€šå·ç§¯ï¼Œä¸Šå±‚bilinear upsamplingã€‚æ§åˆ¶ä¸åŒå±‚çš„ä¸åŒstrideæ¥è·å¾—ç›¸åŒå¤§å°çš„è¾“å‡ºï¼Œå¹¶ç›¸åŠ ã€‚æ—¶é—´æˆæœ¬ä¸º1.5å€

![image-20200704214032431](Figures/image-20200704214032431.png)

BNä¿®æ”¹ä¸ºæ•´ä¸ªç‰¹å¾é‡‘å­—å¡”å±‚å…±äº«ç»Ÿè®¡é‡ï¼Œæ•ˆæœç±»ä¼¼sync_bnï¼ŒåŒæ­¥ä¸åŒä½ç½®ä¸Šçš„ç»Ÿè®¡é‡ï¼Œç»Ÿè®¡èŒƒå›´æ›´å¹¿

BN = standardization($\mu$,$\sigma$) + scale_shift($\gamma$,$\beta$)ï¼Œç»Ÿè®¡å·ç§¯çš„bnä¸ºæ¯å¼ ç‰¹å¾å›¾ï¼Œå³åœ¨channelç»´çš„ç»Ÿè®¡ï¼ˆchannelä¸ªç»Ÿè®¡é‡ï¼‰ï¼Œ**ç»Ÿè®¡ä¸åŒæ ·æœ¬åœ¨åŒä¸€ä¸ªchannelä¸Šæ‰€æœ‰whç‚¹çš„**batch statistics $\mu$å’Œ$\sigma$ï¼ˆreduce at batch dimensionï¼‰ã€‚æ¯å¼ ç‰¹å¾å›¾ä¸€å¯¹parameters $\gamma$å’Œ$\beta$ ï¼ˆhttps://zhuanlan.zhihu.com/p/43200897ï¼‰

å¯ä»¥è¯æ˜PConvèƒ½å¤Ÿæå–Gaussian Pyramid(ä¸åŒé«˜æ–¯æ¨¡ç³Šæ ¸å¯¹å›¾ç‰‡å¤„ç†) å°ºåº¦ä¸å˜çš„ç‰¹å¾ï¼Œå³å¦‚æœåŸå›¾ç‰©ä½“å°ºåº¦å˜åŒ–ï¼Œåˆ™å¯é€šè¿‡å¯¹PConvæå–çš„ç‰¹å¾shiftå¾—åˆ°æ”¹å˜åç‰©ä½“çš„ç‰¹å¾ *<u>è®ºæ–‡ä¸­æœ‰è¯æ˜</u>*

**Scale-Equalizing Pyramid Conv** `SEPC`: PConvçš„å‡çº§ç‰ˆï¼Œé€šè¿‡deformable convå®ç°å¯¹ä¸åŒå°ºåº¦ç‰¹å¾çš„å¯¹é½ã€‚

```python
def pconv_module_forward(x, conv2D_list):
	# x: input feature list [p3,p4,p5,p6,p7] # conv2D_list: conv2D module list,
	# [nn.Conv2D(stride=2),nn.Conv2D(),nn.Conv2D()]
	out_x = []
	for level in range(len(x)):
		tmp = conv2D_list[1](x[level])
		if level > 0:
			tmp += conv2D_list[0](x[level-1])
		if level < len(x) - 1:
			tmp += Upsample(conv2D_list[2](x[level+1])
		out_x.append(tmp) 
	return out_x
```

æœ€åº•å±‚æ™®é€šå·ç§¯kernel sizeä¸å˜ï¼Œå…¶ä»–å±‚ä½¿ç”¨deformable conv

![image-20200704213956083](Figures/image-20200704213956083.png)

å› ä¸ºfeature pyramidä¸­ç”±äºbackboneéçº¿æ€§æ“ä½œï¼Œç›¸å¯¹äºgaussian pyramidç‰¹å¾ä¸å¯¹é½ï¼Œæ‰€ä»¥åªé€šè¿‡dilationæå–ç‰¹å¾ä¸å…¨é¢ï¼Œæ”¹ç”¨d-conv

*SEPC is an improved version of pconv, to relax the discrepancy of feature pyramid from a Gaussian pyramid by aligning the feature map of higher layers with the lowest layer*

åº•å±‚ç‰¹å¾é‡‡ç”¨æ™®é€šå·ç§¯ï¼Œå·ç§¯ç»“æœä½œä¸ºæƒé‡å‘ä¸Šå±‚çš„d-convå…±äº«ï¼ˆå·ç§¯ç»“æœä½œä¸ºd-convçš„ä¸€ä¸ªè¾“å…¥æ±‚offsetï¼Œç±»ä¼¼CentripetalNetä¸­ï¼‰

SEPCæ¨¡å—ç”¨äºå–ä»£RetinaNetçš„detection headçš„å·ç§¯æ¨¡å—

æœ¬è´¨ä¸ºä¸€ç§pix-wise or fine-grained çš„feature fusionï¼Œå¤šå°ºåº¦ç‰¹å¾å›¾é€šè¿‡å·ç§¯æ“ä½œè¿›è¡Œç‰¹å¾èåˆ

![image-20200704214335943](Figures/image-20200704214335943.png)

æ€§èƒ½æå‡æ˜æ˜¾

![image-20200704214411536](Figures/image-20200704214411536.png)

---

## PSConv: Squeezing Feature Pyramid into One Compact Poly-Scale Convolutional Layer

> æå–å¤šå°ºåº¦ç‰¹å¾

ä¸€ä¸ªå·ç§¯æ ¸ä¸åŒé€šé“ä¸åŒdilation rateï¼ˆä¸åŒé¢œè‰²è¡¨ç¤ºä¸åŒdilateï¼‰

![image-20200717174956433](Figures/image-20200717174956433.png)

$\mathcal{H}_{c, x, y}=\sum_{k=1}^{C_{i n}} \sum_{i=-\frac{K-1}{2}}^{\frac{K-1}{2}} \sum_{j=-\frac{K-1}{2}}^{\frac{K-1}{2}} \mathcal{G}_{c, k, i, j} \mathcal{F}_{k, x+i D_{(c, k)}, y+j D_{(c, k)}}$

æ‰©å¼ ç‡åœ¨iné€šé“ä¸Šå¾ªç¯äº¤æ›¿æ’å¸ƒï¼ˆğŸ‘†T=4å¾ªç¯æ’åˆ—ï¼‰ï¼Œåœ¨outé€šé“ç»´åº¦ä¸Šä¹Ÿå¾ªç¯æ’åˆ—

![image-20200717175208977](Figures/image-20200717175208977.png)

Fast RCNNæ›¿æ¢backboneä¸­æ‰€æœ‰å·ç§¯ï¼ŒFPN neckä¸å˜ï¼Œæå‡2ç‚¹å·¦å³

## Rethinking Classification and Localization for Object Detection (Double-Head RCNN)

> æ£€æµ‹å¤´è¿›è¡ŒåŒè·¯åˆ†æ”¯æ”¹è¿›

äºŒé˜¶æ®µæ£€æµ‹å™¨ä¸­ï¼Œå¯¹proposalå¤„ç†çš„ä¼ ç»Ÿæ£€æµ‹å¤´é‡‡ç”¨convå±‚ï¼Œæˆ–è€…fast rcnnä½¿ç”¨fcå±‚å¤„ç†

![image-20200706183720979](Figures/image-20200706183720979.png)

fcå±‚ä½œä¸ºheadï¼Œç”±äºå…¨è¿æ¥æ“ä½œä¸åŒä½ç½®æƒé‡ä¸å…±äº«ï¼Œå¯¹äºä½ç½®æ›´åŠ æ•æ„Ÿï¼ˆå°ä½ç½®å˜åŒ–å¤§çš„è¾“å‡ºç»“æœå˜åŒ–ï¼‰ï¼Œé€‚åˆåˆ†ç±»

convå±‚ä½œä¸ºheadï¼Œç”±äºå·ç§¯æ“ä½œä¸åŒä½ç½®æƒé‡å…±äº«ï¼Œé€‚åˆå›å½’æ•´ä¸ªç‰©ä½“ï¼ˆcoco2018ç»“æœè¡¨æ˜å¯ä»¥ä½¿ç”¨convå±‚ä½œä¸ºbboxçš„é¢„æµ‹å¤´ï¼‰

![image-20200706185341027](Figures/image-20200706185341027.png)

åˆ†æconvä½œä¸ºheadçš„åˆ†ç±»å›å½’ç»“æœğŸ‘‡

![image-20200706184401851](Figures/image-20200706184401851.png)

fcä½œä¸ºheadçš„åˆ†ç±»å›å½’ç»“æœğŸ‘†

1. åˆ†ç±»ï¼šfcä½œä¸ºheadæ—¶ï¼Œå…¶é«˜iouéƒ¨åˆ†åˆ†ç±»ç»“æœæ˜æ˜¾æ¯”convä½œä¸ºheadå¥½ã€‚è®¡ç®—Pearson correlation coefficientğŸ‘‡fc-headçš„score-iouå…³ç³»å¤§äºconv-headçš„score-iouå…³ç³»

![image-20200706184732698](Figures/image-20200706184732698.png)

2. å®šä½ï¼šconv-headç•¥å¥½äºfc-head

å¯è§†åŒ–å…³è”å…³ç³»ï¼šconv-headé‡‡ç”¨å¾—åˆ°çš„ç‰¹å¾å›¾cosè·ç¦»ï¼Œ7x7gridï¼Œæ¯ä¸ªç‚¹äº§ç”Ÿ7x7å¤§å°çš„å’Œå…¶ä»–ä»»æ„ç‚¹çš„å…³è”çŸ©é˜µï¼›fc-headå¯¹fcå±‚æƒé‡å˜æ¢è¾“å‡º7x7ç‰¹å¾å›¾

![image-20200706185049024](Figures/image-20200706185049024.png)

conv-headè®¡ç®—çš„ç‚¹å’Œå‘¨å›´å…³è”å…³ç³»å¤§

#### Double head RCNN

ä¸¤ä¸ªåˆ†æ”¯ï¼Œconv-headç”¨äºå›å½’ï¼Œfc-headç”¨äºåˆ†ç±»

![image-20200706185402627](Figures/image-20200706185402627.png)

æ”¹è¿›ï¼šextendï¼Œè®­ç»ƒæ—¶åˆ©ç”¨conv-headçš„åˆ†ç±»æŸå¤±å’Œfc-headçš„å›å½’æŸå¤±è¿›è¡Œç›‘ç£(unfocused task supervision)

$\mathcal{L}^{f c}=\lambda^{f c} L_{c l s}^{f c}+\left(1-\lambda^{f c}\right) L_{r e g}^{f c}$, $\mathcal{L}^{c o n v}=\left(1-\lambda^{c o n v}\right) L_{c l s}^{c o n v}+\lambda^{c o n v} L_{r e g}^{c o n v}$

åŒæ—¶å¯¹åˆ†ç±»åˆ†æ•°è¿›è¡ŒäºŒåˆ†æ”¯èåˆ(classifiers are complimentary)

![image-20200706185811416](Figures/image-20200706185811416.png)

FPN+2.5~3.8 val AP

---

## D2Det: Towards High Quality Object Detection and Instance Segmentation

> ä¸€é˜¶æ®µå›å½’åˆ†æ”¯æ“ä½œç§»æ¤åˆ°äºŒé˜¶æ®µ
>
> deformable pooling + weighted pooling

![image-20200706234538094](Figures/image-20200706234538094.png)

#### Dense local regression

æŠŠRoIçœ‹ä½œç±»ä¼¼ä¸€é˜¶æ®µä¸­çš„ç‰¹å¾å›¾ã€‚ä¹‹å‰äºŒé˜¶æ®µæ£€æµ‹å™¨å¯¹äºä¸€ä¸ªRoIåªé¢„æµ‹ä¸€ä¸ªæ¡† (FC+é¢„æµ‹)ï¼Œæ”¹æˆRoIä¸­æ¯ä¸ªç‚¹éƒ½é¢„æµ‹ä¸€ä¸ªæ¡†(dense prediction)ã€‚é¢„æµ‹ä¸­é—´ç‚¹åˆ°boxä¸Šä¸‹å·¦å³çš„è·ç¦» (FCOS)

å¢åŠ binary overlap prediction ($\hat{m}$)ï¼Œå¯¹RoIå’ŒGTé‡å éƒ¨åˆ†ä¸º1ï¼Œåªæœ‰ä¸º1çš„ç‚¹çš„é¢„æµ‹ç»“æœæœ‰æ•ˆã€‚

<u>ç±»ä¼¼</u>ä¸€é˜¶æ®µä¸­æ¯ç‚¹é¢„æµ‹bboxï¼Œé¢„æµ‹IoU/objectness

#### Discriminative RoI pooling

<u>deformable pooling + weighted pooling</u>

poolingçš„weightedæƒé‡é€šè¿‡è¾“å…¥ç‰¹å¾æ“ä½œå¾—åˆ°ï¼ˆç±»ä¼¼self-attentionï¼‰ğŸ‘‡Wä¸ºè®¡ç®—çš„æƒé‡

$\tilde{F}=W(F) \odot F$

![image-20200707000247234](Figures/image-20200707000247234.png)æ€§èƒ½æå‡è¾ƒæ˜æ˜¾: multi-scale 50.1

---

## NMS by Representative Region: Towards Crowded Pedestrian Detection by Proposal Pairing (PBM)

>åŸºäºbi-box regre. æ ¹æ®visæ¡†è¿›è¡ŒNMS

è¡Œäººæ£€æµ‹ä¸­é‡å ï¼Œç±»å†…é‡å Replusion Losså’ŒAggLossæƒ©ç½šä¸¤ä¸ªäººä¸­é—´çš„boxï¼Œä½†æ˜¯boxçš„é‡å ä»ç„¶ä¼šå¯¼è‡´åœ¨NMSè¿‡ç¨‹ä¸­è¢«è¯¯åˆ 

Adaptive NMSä¸­GT-densityå’ŒPred-densityçš„inconsistency

![image-20200707105643820](Figures/image-20200707105643820.png)

GTæ¡†ä¸å¯†é›†ï¼Œä½†Pred-boxæ˜¯å¯†é›†çš„ã€‚Adaptive NMSé¢„æµ‹GTçš„å¯†é›†ç¨‹åº¦ï¼Œè€ŒNMSå’ŒPredçš„å¯†é›†ç¨‹åº¦æœ‰å…³ã€‚ğŸ‘†é¢„æµ‹ç»¿æ¡†ä¸å¯†é›†ï¼Œæ‰€ä»¥çº¢æ¡†ä¸ä¼šè¢«ä¿ç•™

#### NMS by representative region

é€šè¿‡è®¡ç®—visibleéƒ¨åˆ†çš„IoUè€Œä¸æ˜¯fulléƒ¨åˆ†çš„IoUè¿›è¡ŒNMS

é‡å ä¸åŒç‰©ä½“çš„æ£€æµ‹æ¡†full-IoUå¤§ï¼Œvis-IoUå°ã€‚é‡å åŒä¸€ç‰©ä½“full-IoUå’Œvis-IoUéƒ½å¤§ $\to$ vis-IoUåˆ¤åˆ«

![image-20200707132234249](Figures/image-20200707132234249.png)

#### Paired BBox Faster RCNN

Paired RPN + Paired Proposal Feature Extractor +  Pair RCNN

##### Paired RPN

GTæ ‡æ³¨ä¸ºpair Q=(F,V)ï¼Œå…¨èº«æ¡†å’Œå¯è§æ¡†

**ä»ä¸€ä¸ªanchor**å›å½’å‡ºfullå’Œvisibleçš„proposalï¼ˆä¸ºäº†inherent correspondenceï¼‰

anchorå’Œä¸€å¯¹GTæ ‡æ³¨çš„åŒ¹é…æ ‡å‡†ï¼š

$\operatorname{IoU}(\mathrm{A}, \mathrm{F}) \geq \alpha_{1}$ and $\operatorname{IoF}(\mathrm{A}, \mathrm{V}) \geq \beta_{1}$

$\operatorname{IoU}(\mathrm{A}, \mathrm{F})=\frac{\operatorname{Area}(\mathrm{A} \cap \mathrm{F})}{\operatorname{Area}(\mathrm{A} \cup \mathrm{F})},\;\;\operatorname{IoF}(\mathrm{A}, \mathrm{V})=\frac{\operatorname{Area}(\mathrm{A} \cap \mathrm{V})}{\operatorname{Area}(\mathrm{V})}$

fullå’Œvisçš„å›å½’è®­ç»ƒç­–ç•¥åŒbi-box regression

##### Paired Proposal Feature Extractor

èåˆfull/visä¸¤ä¸ªproposalçš„ç‰¹å¾

![image-20200707133322847](Figures/image-20200707133322847.png)

<font color="#00dd00">ç»¿è‰²åˆ†æ”¯</font>+<font color="dd0000">çº¢è‰²åˆ†æ”¯</font>ï¼šç®€å•çš„concatä¸¤ä¸ªproposalçš„ç‰¹å¾å‘é‡

<font color="00dd00">ç»¿è‰²åˆ†æ”¯</font>+é»‘è‰²åˆ†æ”¯ï¼švisible region attention/maskï¼Œæ„å»ºvisibleéƒ¨åˆ†çš„0/1 maskï¼Œä¸fullç‰¹å¾$F_f$ç‚¹ä¹˜å¾—$F_m$ï¼Œå†concat $F_m$å’Œ$F_v$

##### Paired RCNN

èåˆç‰¹å¾å’Œproposalä½œä¸ºè¾“å…¥ï¼Œä¸¤ä¸ªåˆ†æ”¯åˆ†åˆ«é¢„æµ‹fullå’Œvisçš„æ£€æµ‹æ¡†

proposalå’Œä¸€å¯¹GTçš„åŒ¹é…æ ‡å‡†ï¼š

$\operatorname{IoU}\left(\mathrm{P}_{\mathrm{f}}, \mathrm{F}\right) \geq \alpha_{2}$ and $\operatorname{IoU}\left(\mathrm{P}_{\mathrm{v}}, \mathrm{V}\right) \geq \beta_{2}$

æ€§èƒ½æå‡æ˜æ˜¾

![image-20200707134837180](Figures/image-20200707134837180.png)

---

## Hit-Detector: Hierarchical Trinity Architecture Search for Object Detection

>NASæ•´ä½“æœç´¢ï¼ŒåŸºäºFBNet

![image-20200708170606633](Figures/image-20200708170606633.png)

äºŒé˜¶æ®µæ£€æµ‹å™¨ï¼šbackbone + neck(feature pyramid & fusing) + RPN(fixed) + Head

NATSå’ŒDetNASæœç´¢backboneï¼ŒNAS-FPNæœFPNï¼ŒAuto-FPNæœfusingå’ŒHead

å•ç‹¬æœç´¢æ•ˆæœè¾ƒå·®ï¼Œé‡‡ç”¨æ•´ä½“æ¯ä¸ªéƒ¨ä»¶(backbone: $\alpha$, neck: $\beta$, head: $\gamma$)ä¸€èµ·æœç´¢ï¼Œ**end-to-end search**

$\alpha^{*}, \beta^{*}, \gamma^{*}=\underset{\alpha, \beta, \gamma}{\arg \min } \mathcal{L}_{v a l}^{d e t}\left(\alpha, \beta, \gamma, w^{*}(\alpha, \beta, \gamma)\right)=\underset{\alpha, \beta, \gamma}{\arg \min } \mathcal{L}_{v a l}^{d e t}\left(\alpha, \beta, \gamma, \underset{w}{\arg \min } \mathcal{L}_{t r a i n}^{d e t}(\alpha, \beta, \gamma, w)\right)$

æ¯ä¸ªcomponenté‡‡ç”¨é€å±‚æœç´¢ï¼Œæ„å»ºæ¯ä¸ªæ“ä½œç”¨åœ¨æ¯ä¸€å±‚çš„å¾—åˆ†çŸ©é˜µ$\alpha$ï¼Œé€‰æ‹©æ¦‚ç‡

å¯¹ä¸€ä¸ªæ“ä½œç”¨åœ¨ä¸åŒå±‚çš„å¾—åˆ†è¿›è¡ŒL2**æ­£åˆ™åŒ–(column-space regularization)**ï¼Œå‡å°‘å¾—åˆ†çš„æ•°å€¼å¤§å°ï¼š

$\min _{\alpha} f(\alpha)+\mu \min _{i}(\sqrt{\sum_{l=1}^{L} \alpha_{l, i}^{2}})$

é€‰æ‹©$\alpha_{l,i}$æœ€å¤§maxçš„ä¸€ä¸ªæ“ä½œï¼Œä½†ä¸ºäº†å¯å¾®é‡‡ç”¨softmaxæ¥é€‰æ‹©(continuous relaxation)

æœç´¢backboneæ—¶æœç´¢ç©ºé—´çš„èŠ‚ç‚¹è®¡ç®—(differentiable)ï¼š$x_{l}=\sum_{o \in \mathcal{O}_{b}} \frac{\exp \left(\alpha_{l}^{o}\right)}{\sum_{o^{\prime} \in \mathcal{O}_{b}} \exp \left(\alpha_{l}^{o^{\prime}}\right)} o\left(x_{l-1}\right)$

æœç´¢neckæ—¶æœlateral connectionï¼Œæœç´¢Headæ—¶æœfcé¢„æµ‹å‰çš„block

ä¼˜åŒ–æ—¶å¢åŠ FLOPSçº¦æŸï¼š$\mathrm{C}(\alpha)=\sum_{l} \sum_{o \in \mathcal{O}_{b}} \alpha_{l}^{o} \mathrm{FLOPs}(o, l)$

é¦–å…ˆå›ºå®š$\{\alpha,\beta,\gamma\}$åœ¨ä¸€åŠçš„æ•°æ®ä¸Šè®­ç»ƒæ±‚$\partial \mathcal{L}/\partial \mathcal{w}$æ›´æ–°$w$ï¼Œå†å›ºå®š$w$åœ¨å‰©ä¸‹çš„æ•°æ®ä¸Šè®­ç»ƒæ±‚$\partial\mathcal{L}/\partial\alpha,\partial\mathcal{L}/\partial\beta,\partial\mathcal{L}/\partial\gamma$æ›´æ–°æ¶æ„$\alpha,\beta,\gamma$

---

## SaccadeNet: A Fast and Accurate Object Detector

![image-20200708225553326](Figures/image-20200708225553326.png)

<u>Center Attentive Module</u>äº§ç”Ÿä¸­å¿ƒç‚¹å’Œç±»åˆ«ï¼›<u>Attention Transitive Module</u>äº§ç”Ÿwhï¼›<u>Aggregation Attentive Module</u>èåˆä¸¤åˆ†æ”¯çš„ç‰¹å¾ï¼ˆåŒçº¿æ€§æ’å€¼ï¼‰å’Œé¢„æµ‹ï¼Œå¹¶å¯¹é¢„æµ‹æ¡†è¿›è¡Œrefineï¼›<u>Corner Attentive Module</u>åªæœ‰ä¸€ä¸ªblockäº§ç”Ÿè§’ç‚¹é¢„æµ‹ï¼Œç”¨äºbackboneç›‘ç£ä¿¡å·ï¼Œæµ‹è¯•æ—¶å»æ‰ã€‚

ç›¸æ¯”CenterNetæ”¹è¿›ï¼š1. é€šè¿‡Aggregationè¿›è¡ŒäºŒæ­¥refine 2. å¢åŠ corneråˆ†æ”¯çš„ç›‘ç£ä¿¡å·æœ‰åŠ©äºå¯¹è¾¹ç¼˜çš„æ£€æµ‹ï¼ˆå¸®åŠ©é¢„æµ‹whçš„åˆ†æ”¯ï¼‰ 3. L1ä½œä¸ºboxè®­ç»ƒæŸå¤±

![image-20200708230331922](Figures/image-20200708230331922.png)

ğŸ‘†<u>test-dev</u>ä¸Šæ€§èƒ½ï¼Œé€Ÿåº¦æå‡æ˜æ˜¾ï¼Œå¿«äºyolov3

---

## Learning from Noisy Anchors for One-stage Object Detection

> losså‡½æ•°å¢åŠ æƒé‡ï¼Œé€‰æ‹©å›å½’åˆ†ç±»åˆ†æ•°é«˜çš„æ¡†å¢å¤§å…¶lossè´¡çŒ®
>
> å¯¹losså­¦ä¹ æ—¶çš„ä¿®æ”¹

ä¹‹å‰çš„æ£€æµ‹å™¨è¯„ä»·anchorå¥½åä½¿ç”¨IoUï¼Œharshçš„åˆ’åˆ†å¯¼è‡´å™ªå£°å’Œä¸æ˜“è®­ç»ƒ

<img src="Figures/image-20200711120826876.png" alt="image-20200711120826876" style="zoom:30%;" />

æ‹–è½¦ï¼šIoUå¤§ä½†åŒ…å«å…¶ä»–ç‰©ä½“ï¼›é•¿é¢ˆé¹¿ï¼šåŒ…å«å…³é”®ç‰¹å¾ä½†IoUå°

ä»¥IoUä½œä¸ºæ­£è´Ÿæ ·æœ¬åˆ’åˆ†ä¼šå¯¼è‡´å™ªå£°ï¼Œéœ€è¦æ ¹æ®<u>å›å½’åˆ†ç±»ç»“æœ(cleanliness)</u>åˆ’åˆ†

**åˆ†ç±»ä¸Š**é‡‡ç”¨å¯¹cleanlinessçš„é¢„æµ‹ä»£æ›¿ä¹‹å‰æ ¹æ®IoUçš„pos/negçš„0/1é¢„æµ‹ï¼ŒRPNçš„**soft-label**ï¼Œ<u>ç±»ä¼¼IoU-Netçš„é¢„æµ‹IoU/soft-objectness</u>

$c=\left\{\begin{array}{ll}\alpha \cdot \text{loc_acc}+(1-\alpha) \cdot \text { cls_conf } & \text { for } b \in \mathcal{A}_{p o s} \\ 0 & \text { for } b \in \mathcal{A}_{n e g}\end{array}\right.$

å¯¹æŒ‰IoUåˆ’åˆ†çš„$\mathcal{A}_{pos}$ä¸­éƒ¨åˆ†è¾ƒé«˜IoUçš„anchorè®¡ç®—cleanlinessï¼Œå³å›å½’åˆ†ç±»çš„æ€§èƒ½

ç¨³å®šè®­ç»ƒï¼Œå‰å‡ ä¸ªiteré‡‡ç”¨anchor-gtçš„IoUè€Œä¸æ˜¯é¢„æµ‹ç»“æœçš„IoUè®¡ç®—c

$L_{c l s} =\sum_{i}^{\mathcal{A}_{p o s}} r_{i} \operatorname{BCE}\left(p_{i}, c_{i}\right)+\sum_{j}^{\mathcal{A}_{n e g}} \operatorname{BCE}\left(p_{j}, c_{j}\right)$ï¼Œç”¨äºRPNæˆ–objectnessé¢„æµ‹

**å®šä½ä¸Š**é‡‡ç”¨æ ¹æ®c**å¯¹$\mathcal{A}_{pos}$ä¸­**anchorè®¡ç®—**reweight** rï¼Œå¯¹anchorå›å½’<u>æŸå¤±åŠ æƒ</u>ã€‚$\operatorname{loc\_a}$ä¸ºboxå’Œ**åŒ¹é…åˆ°çš„**GTçš„IoUï¼ˆåŒ¹é…ç”¨æœ€å¤§IoUæ–¹æ³•ï¼‰

$r=\left(\alpha \cdot f\left(\text{loc_a}\right)+(1-\alpha) \cdot f\left(\text{loc_c}\right)\right)^{\gamma}$ï¼Œå…¶ä¸­$f(x)=\frac{1}{1-x},\;\gamma=1$ï¼Œä¸ºå¢å¤§varianceï¼Œå¹¶å°†$r$å‡å€¼æ­£åˆ™åŒ–åˆ°1

$ L_{r e g} =\sum_{i}^{\mathcal{A}_{p o s}} r_{i} \operatorname{smooth}_{-} \ell_{1}$

<img src="Figures/image-20200711123828365.png" alt="image-20200711123828365" style="zoom:50%;" />

---

## CSPNet: A New Backbone that can Enhance Learning Capability of CNN

> ä½¿ç”¨å·ç§¯å±‚æˆªæ–­æ¢¯åº¦ï¼Œå‡å°‘ç›´æ¥ç›¸è¿ï¼Œé˜²æ­¢æ¢¯åº¦é‡å¤è®¡ç®—

densenetä¸­ä¸æ–­çš„concatä¼šè®©æ¢¯åº¦åä¼ æ—¶åé¢çš„æ¢¯åº¦ä¸æ–­ä¼ åˆ°å‰é¢ï¼Œè®¡ç®—é‡å¤§ï¼Œé‡å¤è®¡ç®—

$\begin{aligned} x_{1} &=w_{1} * x_{0} \\ x_{2} &=w_{2} *\left[x_{0}, x_{1}\right] \\ & \vdots \\ x_{k} &=w_{k} *\left[x_{0}, x_{1}, \ldots, x_{k-1}\right] \end{aligned}$

åä¼ 

$\begin{aligned} w_{1}^{\prime} &=f_{1}\left(w_{1}, \left\{ g_{0}\right\}\right) \\ w_{2}^{\prime} &=f_{2}\left(w_{2},\left\{g_{0}, g_{1}\right\}\right) \\ w_{k}^{\prime} &=f_{k}\left(w_{k},\left\{g_{0},g_{1}, \ldots, g_{k-1}\right\}\right) \end{aligned}$

ä¾‹å¦‚åœ¨æœ€åä¸€å±‚è®¡ç®—è¿‡ç¨‹ä¸­ï¼Œç”±äºå’Œå‰é¢å±‚ç›´æ¥è¿æ¥ï¼Œæ¢¯åº¦ä¼šä¸€ç›´å›ä¼ åˆ°w1

æå‡ºï¼š**Partial Dense Block** è¾“å…¥ç‰¹å¾channelä¸Šåˆ†ä¸ºä¸¤éƒ¨åˆ†$\left[x_0^\prime,\;x_0^{\prime\prime}\right]$ï¼Œä¸€éƒ¨åˆ†ç›´æ¥ç›¸è¿ï¼Œå¦å¤–éƒ¨åˆ†dense blockã€‚**Partial Transition Layer** èåˆæ—¶é‡‡ç”¨transitionå±‚æˆªæ–­æ¢¯åº¦çš„ä¼ æ’­

![image-20200724223413132](Figures/image-20200724223413132.png)

$\begin{aligned} x_{k} &=w_{k} *\left[x_{0}^{\prime\prime}, x_{1}, \ldots, x_{k-1}\right] \\ x_{T} &=w_{T} *\left[x_{0}^{\prime\prime}, x_{1}, \ldots, x_{k}\right] \\ x_{U} &=w_{U} *\left[x_{0}^{\prime}, x_{T}\right] \\ w_{k}^{\prime} &=f_{k}\left(w_{k},\left\{g_{0}^{\prime \prime}, g_{1}, \ldots, g_{k-1}\right\}\right) \\ w_{T}^{\prime} &=f_{T}\left(w_{T},\left\{g_{0}^{\prime \prime}, g_{1}, \ldots, g_{k}\right\}\right) \\ w_{U}^{\prime} &=f_{U}\left(w_{U},\left\{g_{0}^\prime, g_{T}\right\}\right) \end{aligned}$

$w_{U}$çš„æ¢¯åº¦åªä¼ é€’åˆ°$w_T$ï¼Œä¹‹åæ¢¯åº¦å…¨éƒ¨ä»$w_T$å¼€å§‹ä¼ 

![image-20200724222732419](Figures/image-20200724222732419.png)

Fusion firstèƒ½æˆªæ–­æ›´å¤šæ¢¯åº¦ä¼ é€’ï¼ˆå¦‚åç»­éƒ¨åˆ†åˆ°part1çš„æ¢¯åº¦ï¼‰ï¼Œä½†æ€§èƒ½è¾ƒå·®ï¼›é‡‡ç”¨fusion last

æå‡ºEFMï¼Œä¸´è¿‘å±‚ç‰¹å¾èåˆï¼Œé˜²æ­¢distract

![image-20200724223519751](Figures/image-20200724223519751.png)

æ£€æµ‹ä»»åŠ¡æ€§èƒ½æå‡æ˜æ˜¾

---

## Feature Pyramid Transformer

> é‡‡ç”¨transformer/self-attentionæ–¹å¼è¿›è¡Œå¤šå°ºåº¦ç‰¹å¾èåˆ/äº¤äº’

Non-localåªå¯¹åŒä¸€å°ºåº¦çš„ä¸åŒç©ºé—´ç‰¹å¾äº¤äº’ï¼Œæ”¹è¿›space+scale

![image-20200818143118059](Figures/image-20200818143118059.png)

ä¸åŒå±‚çš„ä¸åŒç©ºé—´ä½ç½®çš„ç‰©ä½“interactionï¼ˆco-occurring in multiple scalesï¼‰

#### Non-local

ç”¨äºä¸€å¼ ç‰¹å¾å›¾ä¸åŒä½ç½®ç‰¹å¾ã€‚çœ‹ä½œself-attentionï¼Œè¾“å…¥$\mathbf{q}_i=f_q(\mathbf{X}_i)$è¡¨ç¤º$i$ä½ç½®<u>ç»è¿‡$f_q$æå–å</u>çš„queryï¼Œ$\mathbf{k}_j=f_k(\mathbf{X}_j)$ä¸ºkeyï¼Œ$\mathbf{v}_j=f_v(\mathbf{X}_j)$ä¸º$j$ä½ç½®çš„value

å…ˆdot productè®¡ç®—i-queryå’Œj-keyç›¸ä¼¼åº¦ï¼Œsoftmaxæ ‡å‡†åŒ–å¾—åˆ°æƒé‡ï¼Œå’Œj-valueç›¸ä¹˜çš„åˆ°ç»“æœ

$\begin{aligned} \text { Input: } & \mathbf{q}_{i}, \mathbf{k}_{j}, \mathbf{v}_{j} \\ \text { Similarity: } & s_{i, j}=F_{\text {sim}}\left(\mathbf{q}_{i}, \mathbf{k}_{j}\right) \\ \text { Weight: } & w_{i, j}=F_{\text {nom}}\left(s_{i, j}\right) \\ \text { Output: } & \tilde{\mathbf{X}}_{i}=F_{\text {mul}}\left(w_{i, j}, \mathbf{v}_{j}\right), \end{aligned}$

#### Self-Transformer (ST)

ç”¨äºä¸€å¼ å›¾ä¸Šco-occurringç‰©ä½“ç‰¹å¾ã€‚æŠŠqueryå’Œkeyåˆ†æˆ$N$ä»½ï¼Œæ¯éƒ¨åˆ†è®¡ç®—ç›¸ä¼¼åº¦$s_{i, j}^{n}=F_{s i m}\left(\mathbf{q}_{i, n}, \mathbf{k}_{j, n}\right)$ï¼Œä½¿ç”¨Mixture of Softmaxä½œä¸ºæ ‡å‡†åŒ–å‡½æ•°ï¼ˆåŠ æƒæ±‚å’Œ$\pi_n$ï¼‰

$w_{i,j} = F_{\operatorname{mos}}(s_{i, j}^{n})=\sum_{n=1}^{\mathcal{N}} \pi_{n} \frac{\exp (s_{i, j}^{n})}{\sum_{j} \exp (s_{i, j}^{n})}$

<img src="Figures/image-20200818145143482.png" alt="image-20200818145143482" style="zoom:50%;" />

#### Grounding Transformer (GT)

top-downèåˆï¼Œgroundé«˜å±‚conceptç‰¹å¾åˆ°ä½å±‚pixelç‰¹å¾ï¼Œé«˜å±‚$k\;v$ä½å±‚$q$

é‡‡ç”¨è´Ÿæ¬§å¼è·ç¦»è®¡ç®—ä¸åŒå±‚ä¹‹é—´ç‰¹å¾ç›¸ä¼¼åº¦ $F_{\text {eud}}\left(\mathbf{q}_{i}, \mathbf{k}_{j}\right)=-\left\|\mathbf{q}_{i}-\mathbf{k}_{j}\right\|^{2}$

$\mathbf{q}_i=f_q(\mathbf{X}_i^f)$è¡¨ç¤º$f$å±‚$i$ä½ç½®çš„ç‰¹å¾ï¼Œ$\mathbf{k}_j=f_K(\mathbf{X}_j^c)$è¡¨ç¤º$c$å±‚$j$ä½ç½®ï¼Œè®¡ç®—çš„åˆ°$\mathbf{\hat{X}}_i^f$

åˆ†å‰²ä»»åŠ¡éœ€è¦å±€éƒ¨ä¿¡æ¯ï¼Œä¼ ç»Ÿé‡‡ç”¨ç›´æ¥ç›¸åŠ ï¼Œè€Œç”¨GTä¼šå¸¦æ¥å…¨å±€ä¿¡æ¯ï¼Œæå‡º**Locality-constrained Grounding Transformer**ï¼Œ$\mathbf{q}_i$åªå’Œä¸€éƒ¨åˆ†$\mathbf{k}_j\;\mathbf{v}_j$äº¤äº’

<img src="Figures/image-20200818145429855.png" alt="image-20200818145429855" style="zoom:50%;" />

#### Rendering Transformer (RT)

bottom-up, rendering high-level concept with low-level pixels

ä½å±‚çš„$\mathbf{K}$å’Œ$\mathbf{V}$ï¼Œé«˜å±‚ä¸º$\mathbf{Q}$

 $\mathbf{K}$é¦–å…ˆGAPè®¡ç®—ä¸ºæƒé‡$\mathbf{w}$ï¼Œæƒé‡$\mathbf{w}$å†å’Œ$\mathbf{Q}$ç›¸ä¹˜refineï¼Œæœ€åå’Œdownsample (conv+stride)çš„$\mathbf{V}$ç›¸åŠ 

$\begin{aligned} \text { Input: } & \mathbf{Q}, \mathbf{K}, \mathbf{V} \\ \text { Weight: } & \mathbf{w}=G A P(\mathbf{K}) \\ \text { Weight Query: } & \mathbf{Q}_{a t t}=F_{a t t}(\mathbf{Q}, \mathbf{w}) \\
\text{Down-sampled Value: } & \mathbf{V}_{d o w}=F_{sconv}(\mathbf{V})\\
\text{Output: } & \hat{\mathbf{X}}^{c}=F_{a d d}\left(F_{\text {conv }}\left(\mathbf{Q}_{a t t}\right), \mathbf{V}_{\text {dow}}\right)\end{aligned}$

#### æ€»ä½“æ¶æ„

resnetï¼Œfaster rcnn head

![image-20200818150612705](Figures/image-20200818150612705.png)

é«˜å±‚è®¡ç®—ç”¨äºGTçš„ç‰¹å¾ï¼Œä½å±‚è®¡ç®—ç”¨äºRTçš„ç‰¹å¾ï¼Œtransformerèåˆçš„åˆ°æ–°ç‰¹å¾ï¼Œconcat

å‚æ•°é‡ï¼Œè®¡ç®—é‡å¢åŠ å¤§

---

## BorderDet: Border Feature for Dense Object Detection

> explicit border information

![image-20200819230010228](Figures/image-20200819230010228.png)

borderdetå¢å¼ºäº†è¾¹ç¼˜çš„ç‰¹å¾

#### Border Align

åŸå§‹ç‰¹å¾é€šé“æ•°ä¸ºCï¼Œæ„å»º5Cé€šé“çš„ç‰¹å¾ï¼Œè¡¨ç¤ºä¸Šä¸‹å·¦å³ç‰¹å¾å’ŒåŸå§‹ç‚¹çš„ç‰¹å¾ã€‚è¾“å…¥coarse box regçš„bboxã€‚

å¯¹äºæ¯ä¸ªijç‚¹ï¼Œ4Cåˆ†åˆ«é€‰æ‹©å…¶å¯¹åº”é¢„æµ‹æ¡†çš„è¾¹ä¸Šå“åº”æœ€å¤§çš„ç‰¹å¾ä½œä¸ºè¿™ä¸ªç‚¹çš„è¾“å‡ºç‰¹å¾ï¼ˆ+åŸå§‹ç‰¹å¾=5C x W x Hç‰¹å¾å›¾ï¼‰

$F_{c}(i, j)=\left\{\begin{array}{ll}I_{c}(i, j) & 0 \leq c<C \\ \max _{0 \leq k \leq N-1}\left(I_{c}\left(x_{0}, y_{0}+\frac{k h}{N}\right)\right) & C \leq c<2 C \\ \max _{0 \leq k \leq N-1}\left(I_{c}\left(x_{0}+\frac{k w}{N}, y_{0}\right)\right) & 2 C \leq c<3 C \\ \max _{0 \leq k \leq N-1}\left(I_{c}\left(x_{1}, y_{0}+\frac{k h}{N}\right)\right) & 3 C \leq c<4 C \\ \max _{0 \leq k \leq N-1}\left(I_{c}\left(x_{0}+\frac{k w}{N}, y_{1}\right)\right) & 4 C \leq c<5 C\end{array}\right.$

$(i,j)$çš„coarseé¢„æµ‹ç»“æœä¸º$(x_0,y_0,x_1,y_1)$

![image-20200819231021412](Figures/image-20200819231021412.png)

![image-20200819231044269](Figures/image-20200819231044269.png)

**Border Alignment Module**å¯¹ç‰¹å¾å‡ç»´ï¼ŒBorderAlignï¼Œé™ç»´ğŸ‘‡

![image-20200819231203928](Figures/image-20200819231203928.png)

BorderDetåˆ†åˆ«åœ¨å®šä½å’Œåˆ†ç±»åˆ†æ”¯ä½¿ç”¨BAMï¼ŒBAMä½¿ç”¨å®šä½åˆ†æ”¯çš„ç¬¬ä¸€æ­¥çš„å®šä½ç»“æœï¼Œå†å»refineï¼Œç»„åˆæˆä¸ºæœ€åè¾“å‡ºğŸ‘‡

<img src="Figures/image-20200819231428705.png" alt="image-20200819231428705" style="zoom:50%;" />

---

## SpineNet: Learning Scale-Permuted Backbone for Recognition and Localization

> NAS+æ£€æµ‹ï¼Œencoder+decoderç»“æ„ä¸å¥½ (scale decreased model)
>
> å°ºåº¦å¢å¤§å‡å°ï¼Œä¸åŒå°ºåº¦ç‰¹å¾è¿æ¥

æå‡ºscale-permuted modelï¼Œä¿è¯ï¼š1. ç‰¹å¾å›¾å°ºåº¦å¯ä»¥éšæ—¶å¢å¤§å‡å° 2. ä¸åŒå°ºåº¦çš„ç‰¹å¾å¯ä»¥è¿æ¥è¿›è¡Œèåˆ

ç›´æ¥æœç´¢æ•´ä¸ªç½‘ç»œï¼Œè€Œä¸æ˜¯åˆ†åˆ«æœç´¢backboneå’Œfpn

![image-20200820204545461](Figures/image-20200820204545461.png)

é€æ­¥æ›¿æ¢resnetğŸ‘‡ï¼Œçº¢è‰²ä¸ºè¾“å‡ºå±‚ï¼Œå¯ä»¥çœ‹ä½œ**backbone+FPN**

![image-20200820205947836](Figures/image-20200820205947836.png)

Multi-scale, DropBlock, stochastic depth, swish activation

æ€§èƒ½æå‡æ˜æ˜¾ mAP=52.1

---

## Dually Supervised Feature Pyramid for Object Detection and Segmentation

> FPN top-downå’Œbotton-upä¸¤æ¬¡éƒ½é¢„æµ‹ç›‘ç£ç®—loss
>
> æ‹†åˆ†clså’Œreg head

1. ![image-20200823190552173](Figures/image-20200823190552173.png)

2. ![image-20200823190617471](Figures/image-20200823190617471.png)

---

## Pyramidal Convolution: Rethinking Convolutional Neural Networks for Visual Recognition

> ä¸€ä¸ªå·ç§¯æ‹†åˆ†ä¸ºå¤šä¸ªä¸åŒreceptive fieldçš„åˆ†ç»„å·ç§¯

![image-20200831204426110](Figures/image-20200831204426110.png)

Bottom-up: æ„Ÿå—é‡é€æ¸å¢å¤§ï¼Œkernelæ·±åº¦$FM_{out-i}$é€æ¸å‡å°

kernel depth (è¾“å‡ºé€šé“æ•°): $\left\{F M_{i}, \frac{F M_{i}}{\left(\frac{K_{2}^{2}}{K_{1}^{2}}\right)}, \frac{F M_{i}}{\left(\frac{K_{3}^{2}}{K_{1}^{2}}\right)}, \ldots, \frac{F M_{i}}{\left(\frac{K_{n}^{2}}{K_{1}^2}\right)}\right\}$

å¯¹SSDæ¨¡å‹æœ‰æå‡

---

## Generalized Focal Loss: Learning Qualified and Distributed Bounding Boxes for Dense Object Detection

> 

1. è®­ç»ƒæ—¶cls-scoreå’Œiou/objectness-scoreå•ç‹¬é¢„æµ‹ä½†æµ‹è¯•æ—¶ç›´æ¥ç›¸ä¹˜
2. bboxæ²¡æœ‰å»ºæ¨¡uncertainty

#### QFL

![image-20200905160302886](Figures/image-20200905160302886.png)

ğŸ‘†IoU(quality)å’Œcls-scoreä¸matchï¼ŒğŸ‘‡ç‹¬ç«‹é¢„æµ‹

![image-20200905160358215](Figures/image-20200905160358215.png)

![image-20200905160432718](Figures/image-20200905160432718.png)

ğŸ‘†ä¼ ç»Ÿä¸ºå†²å‡»å‡½æ•°(Dirac delta dist.)ï¼Œæ— æ³•å»ºæ¨¡ä¸ç¡®å®šæ€§

æå‡ºé¢„æµ‹åˆ†ç±»-è´¨é‡è”åˆè¡¨ç¤ºï¼ˆsmooth labelï¼‰ï¼Œç¦»æ•£labelï¼Œå°†Focal Lossçš„ä¼˜åŒ–æ”¹ $\mathbf{Q F L}(\sigma)=-|y-\sigma|^{\beta}((1-y) \log (1-\sigma)+y \log (\sigma))$ ã€Œå±•å¼€pos+negã€

#### DFL

![image-20200906105358216](Figures/image-20200906105358216.png)

ğŸ‘†ä¹‹å‰æ˜¯å†²å‡»å‡½æ•°ï¼Œåªæœ‰æ ‡æ³¨yå‡ºæ¦‚ç‡æœ€å¤§ï¼Œå…¶ä»–ä¸º0ï¼Œå¯¹äºä¸ç¡®å®šçš„è¾¹ç•Œæ²¡æœ‰ç›‘ç£

![image-20200906110136608](Figures/image-20200906110136608.png)

ğŸ‘†ä¸ç¡®å®šè¾¹ç•Œ bottomï¼ŒåŒå³°

<img src="Figures/image-20200906110316101.png" alt="image-20200906110316101" style="zoom:50%;" />

ä¼ ç»Ÿ $\hat{y}=\int_{-\infty}^{+\infty} \delta(x-y) x \mathrm{d} x$ï¼Œå†²å‡»å‡½æ•°ï¼Œåªé¢„æµ‹ä¸€ç‚¹

æå‡ºé€šè¿‡åˆ†å¸ƒ$P$é¢„æµ‹label $\hat{y}=\int_{-\infty}^{+\infty} P(x) x \mathrm{d} x=\int_{y_{0}}^{y_{n}} P(x) x \mathrm{d} x$ åˆ†å¸ƒçš„ç§¯åˆ†

ä»å†²å‡»å‡½æ•°ï¼Œåˆ°å…ˆéªŒé«˜æ–¯åˆ†å¸ƒï¼Œåˆ°ä»»æ„åˆ†å¸ƒï¼Œå»ºæ¨¡**éšæœºæ€§**

<img src="Figures/image-20200906110336213.png" alt="image-20200906110336213" style="zoom:50%;" />

ç¦»æ•£åŒ– $\hat{y}=\sum_{i=0}^{n} P\left(y_{i}\right) y_{i}$ï¼Œ$\sum_{i=0}^nP(y_i)=1$

å‡å°‘è®¡ç®—é‡ï¼ŒçœŸå®åˆ†å¸ƒä¸æ ‡æ³¨ä½ç½®è·ç¦»ä¸ä¼šå¤ªè¿œï¼Œåªè®¡ç®—å·¦å³æœ€è¿‘ä¸¤ä¸ª$y_l,\;y_r$

$\hat{y}=\sum_{j=0}^{n} P\left(y_{j}\right) y_{j}=\mathcal{S}_{i} y_{i}+\mathcal{S}_{i+1} y_{i+1}=\frac{y_{i+1}-y}{y_{i+1}-y_{i}} y_{i}+\frac{y-y_{i}}{y_{i+1}-y_{i}} y_{i+1}$

$\mathbf{D F L}\left(\mathcal{S}_{i}, \mathcal{S}_{i+1}\right)=-\left(\left(y_{i+1}-y\right) \log \left(\mathcal{S}_{i}\right)+\left(y-y_{i}\right) \log \left(\mathcal{S}_{i+1}\right)\right)$

æœ€åé¢„æµ‹ä¸ºå·¦å³æœ€è¿‘ä¸¤ä¸ªä½ç½®çš„çº¿æ€§ç»„åˆ $\hat{y}=y_l*p_{y_l}+y_r*p_{y_r}\;\left(p_{y_l}+p_{y_r}=1\right)$

#### GFL

QFLå’ŒDFLçš„ç»Ÿä¸€è¡¨ç¤º Generalized Focal Loss

$\mathbf{G F L}\left(p_{y_{l}}, p_{y_{r}}\right)=-\left|y-\left(y_{l} p_{y_{l}}+y_{r} p_{y_{r}}\right)\right|^{\beta}\left(\left(y_{r}-y\right) \log \left(p_{y_{l}}\right)+\left(y-y_{l}\right) \log \left(p_{y_{r}}\right)\right)$

è®­ç»ƒæŸå¤±

$\mathcal{L}=\frac{1}{N_{p o s}} \sum_{z} \mathcal{L}_{\mathcal{QFL}}+\frac{1}{N_{p o s}} \sum_{z} \mathbf{1}_{\left\{c_{z}^{*}>0\right\}}\left(\lambda_{0} \mathcal{L}_{\mathcal{Bbox}}+\lambda_{1} \mathcal{L}_{\mathcal{DFL}}\right)$

å¯¹æ‰€æœ‰ä½ç½®$z$è®¡ç®—QFLï¼Œå¯¹æ­£æ ·æœ¬$c^*_z>0$è®¡ç®—GIoU losså’ŒDFL

DFLå’ŒIoU-lossä¼˜åŒ–bboxå›å½’ï¼Œåˆ†åˆ«å»ºæ¨¡uncertaintyå’ŒIoUæœ€å¤§ï¼›QFLä¼˜åŒ–åˆ†ç±»åˆ†æ”¯

å¯¹å¤§ç›®æ ‡æå‡æ•ˆæœå¥½ï¼Œ+1 mAP

Ref: https://zhuanlan.zhihu.com/p/147691786

---

