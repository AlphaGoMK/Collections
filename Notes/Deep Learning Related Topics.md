# Deep Learning Related Topics

## ResNeXt

> ä¼ ç»Ÿä¸ºå¢åŠ æ·±åº¦ï¼ˆå±‚æ•°ï¼‰å’Œå®½åº¦ï¼ˆç‰¹å¾ç»´åº¦ï¼‰ï¼Œå˜æˆç»“åˆVGGçš„å †å ç½‘ç»œ+Inceptionçš„ _split-transform-merge_ ç­–ç•¥ã€‚å¢åŠ å‡†ç¡®ç‡å’Œå¯æ‰©å±•æ€§åŒæ—¶ä¸æ”¹å˜æˆ–å‡å°å¤æ‚åº¦  

æå‡º<u>**cardinality**</u>ï¼Œè¡¨ç¤ºå¤šåˆ†æ”¯çš„åˆ†æ”¯æ•°é‡ï¼Œmore effective
![](Figures/EC005B55-327B-4F4C-A5FE-9232BA9D04E8.png)
ğŸ‘†å·¦ä¸ºResNetï¼Œå³ä¸ºResNeXt cardinality=32
<u>**å¹³è¡Œå †å **</u>ä»£æ›¿çº¿æ€§åŠ æ·±ï¼Œä¸æ˜¾è‘—å¢åŠ å‚æ•°æ•°é‡çº§å¢åŠ å‡†ç¡®ç‡ï¼›åŒæ—¶å¹³è¡Œåˆ†æ”¯çš„æ‹“æ‰‘ç»“æ„ç›¸åŒå‡å°‘äº†è¶…å‚æ•°ï¼ˆè®¾è®¡æˆæœ¬ï¼‰
![](Figures/C1CCACF2-6F03-4B74-99C6-E8397306F05E.png)
ğŸ‘†split-transform-mergeè¿‡ç¨‹
![](Figures/E210EA79-5D84-4C33-B0BA-146AFABB08A2.png)
ğŸ‘†ä¸‰ç§ç­‰ä»·çš„ç»“æ„ï¼Œç¬¬ä¸‰ç§ç®€æ´ï¼Œé€Ÿåº¦æ›´å¿«

- - - -

## MobileNet

æŠŠä¼ ç»Ÿå·ç§¯å˜æˆdepth-wiseå·ç§¯å’Œ1x1å·ç§¯
æ ‡å‡†å·ç§¯ï¼ˆDkå·ç§¯æ ¸å¤§å°ï¼ŒDfè¾“å‡ºç‰¹å¾å›¾å°ºå¯¸ï¼ŒMè¾“å…¥é€šé“ï¼ŒNè¾“å‡ºé€šé“ï¼‰
$D_K\times D_K\times M\times N\times D_F\times D_F$
**æ·±åº¦å¯åˆ†ç¦»å·ç§¯**ï¼šdepth-wiseå·ç§¯å’Œ`1x1`å·ç§¯

$D_K\times D_K\times M\times D_F\times D_F + M\times N\times D_F\times D_F$

Depthå·ç§¯æŠŠè¾“å…¥ç‰¹å¾å›¾Dk x Dk x MæˆDf x Df x Må±‚ï¼Œç„¶å`1x1`æŠŠMå±‚å˜ä¸ºNå±‚è¾“å‡º
![](Figures/6B22C4FC-30D7-45C9-9CD8-DD3469070EDC.png)
ğŸ‘†<u>**depth-wise conv**</u>ä¸åŒç‰¹å¾å›¾é€šé“ä½¿ç”¨ä¸åŒå·ç§¯æ ¸ï¼ŒMå±‚ç‰¹å¾å›¾å·ç§¯è¿˜æ˜¯Må±‚ï¼ˆä¸ç›¸åŠ ï¼‰æ‰€ä»¥`Dk x Dk x M x Df x Df`ï¼ˆä¸€ä¸ªå·ç§¯æ ¸è®¡ç®—`Dk x Dk`æ¬¡ï¼Œæ„æˆè¾“å‡ºç‰¹å¾å›¾çš„ä¸€ä¸ªç‚¹ï¼Œæ‰€ä»¥ä¸€å¼ è¾“å‡ºç‰¹å¾å›¾ä¸€å…±è®¡ç®—`Dk x Dk x Df x Df`æ¬¡ï¼Œä¸€å…±Må±‚ï¼‰
![](Figures/770C8B8D-2E90-4D9E-99D4-E1BE24CAE3A4.png)
ğŸ‘†depth-wiseè§£é‡Š
![](Figures/C8B12662-17AF-4AE3-8753-17E1F0A5FAC0.png)
ğŸ‘†<u>**point-wise conv**</u>ä¸åŒç‰¹å¾å›¾ä½¿ç”¨åŒä¸€ä¸ªå·ç§¯æ ¸ï¼Œä½†æ˜¯1x1ã€‚æŠŠMé€šé“å·ç§¯æˆNé€šé“ï¼Œæ‰€ä»¥`M x N x Df x Df` ï¼ˆä¸€ä¸ªå·ç§¯æ ¸è®¡ç®—Må±‚ç›¸åŠ ï¼Œå†è®¡ç®—Næ¬¡æ„æˆNé€šé“ï¼‰
![](Figures/B1AE5F5A-4B07-4A4E-A1F3-932F477265B7.png)
ğŸ‘†point-wiseè§£é‡Š

---

## Convolution

![](Figures/B712984B-A621-4D75-B9C1-7DB0D7D0226F.png)
![](Figures/4ECAAE30-D4AB-45FC-A130-F8DE831CC235.png)
å‚æ•°é‡ `H x W x C1 x C2`

## Group Convolution

![](Figures/FB2404B4-04DF-4E98-923F-0E5DDB739C0A.png)
å·ç§¯æ ¸ä¹‹é—´çš„å…³ç³»æ˜¯**ç¨€ç–**çš„ã€‚group convå‡å°‘å·ç§¯æ ¸ä¹‹é—´çš„å…³è”æ€§ï¼Œ **regularization**ï¼Œå‡å°‘è¿‡æ‹Ÿåˆ
Ref: [A Tutorial on Filter Groups (Grouped Convolution) - A Shallow Blog about Deep Learning](https://blog.yani.io/filter-group-tutorial/)

---

## MobileNet V2

å¢åŠ <u>**inverted residual with linear bottleneck**</u>ï¼Œé¦–å…ˆå‡ç»´ï¼Œå·ç§¯ï¼Œå†é™ç»´ã€‚ <u>ç‰¹å¾æå–åœ¨é«˜ç»´ç©ºé—´è¿›è¡Œ</u> ã€‚çººé”¤å½¢ï¼Œå’Œresnetçš„hour-glassç›¸åï¼Œæ‰€ä»¥inverted
åœ¨DWä¹‹å‰ <u>**å¢åŠ PWå·ç§¯**</u>ï¼šä¸Šä¸€å±‚é€šé“æ•°å°‘ï¼Œåˆ™DWåªèƒ½åœ¨ä½ç»´ç©ºé—´æå–ç‰¹å¾ï¼Œå¢åŠ PWåï¼Œå…ˆå‡ç»´ï¼Œå†æDWç‰¹å¾
![](Figures/20A1CAA2-880C-4C27-9475-C66CC955FDA5.png)
å»æ‰äº†ç¬¬äºŒä¸ªPWçš„ <u>**æ¿€æ´»å‡½æ•°**</u> ï¼šåªæœ‰åœ¨é«˜ç»´ç©ºé—´ä¸­ï¼Œæ¿€æ´»å‡½æ•°å¯ä»¥å¢åŠ éçº¿æ€§ï¼›è€Œåœ¨ä½ç»´ç©ºé—´ä¸­ï¼Œæ¿€æ´»å‡½æ•°ä¼šç ´åç‰¹å¾ã€‚å› æ­¤é‡‡ç”¨çº¿æ€§
å¢åŠ  **shortcut** è¿æ¥ï¼Œè¾“å‡ºä¸è¾“å…¥ç›¸åŠ ï¼šåŒResNet

- - - -

## ShuffleNet

> ç»„å†…point-wiseå·ç§¯ï¼Œå¢åŠ shuffleæ“ä½œé€šé“ä¹‹é—´ä¿¡æ¯æ²Ÿé€š  

![](Figures/B747E511-B1B6-4CD8-9F8F-446708466A2B.png)
ğŸ‘†aï¼šnormalï¼Œbï¼šåˆ†ç»„å·ç§¯ï¼Œcï¼šchannel shuffle

#### Channel shuffle

ğŸ‘‡<u>**å±•å¼€ï¼Œè½¬ç½®ï¼Œå¹³é“º**</u>
![](Figures/6C36658F-B3E1-4407-9517-D585F622C5BE.png)
![](Figures/3C97825C-0822-455C-AB65-9D0E27EB706C.png)
ğŸ‘†å¯¹æ¯”mobilenetï¼Œshufflenetå’Œshuffleneté™é‡‡æ ·
ğŸ‘†gé‡‡ç”¨åˆ†ç»„å·ç§¯ï¼Œgå°ï¼›å»æ‰ReLUï¼Œå‡å°‘ä¿¡æ¯æŸè€—ï¼›é™é‡‡æ ·ä¿è¯å‚æ•°é‡ä¸éª¤å‡ï¼Œéœ€è¦å¢åŠ é€šé“æ•°é‡ï¼Œé‡‡ç”¨concatè€Œä¸æ˜¯element-wise add
**æ€§èƒ½è¯„ä»·**ï¼šMACè®¿å­˜ï¼ŒGPUå¹¶è¡Œæ€§
**è®¾è®¡å‡†åˆ™**

* å½“è¾“å…¥é€šé“æ•°å’Œè¾“å‡ºé€šé“æ•°ç›¸åŒæ—¶ï¼ŒMACæœ€å°
* MACä¸åˆ†ç»„æ•°é‡gæˆæ­£æ¯”ï¼ˆè°¨æ…ä½¿ç”¨åˆ†ç»„å·ç§¯ï¼‰
* ç½‘ç»œçš„åˆ†æ”¯æ•°é‡é™ä½å¹¶è¡Œèƒ½åŠ›ï¼ˆå·ç§¯æ ¸åŠ è½½å’ŒåŒæ­¥ï¼‰ï¼Œå•åˆ†æ”¯é€Ÿåº¦å¿«
  * ResNeXtå‡†ç¡®ç‡æå‡ä½†æ˜¯é€Ÿåº¦æ…¢
* Element-wiseæ“ä½œæ˜¯éå¸¸è€—æ—¶

![](Figures/EA15DE00-DC00-4A95-B656-20AA985E0269.png)
ğŸ‘†shufflenet v2å’Œdownsample
å¢åŠ **é€šé“åˆ†å‰²**ï¼Œé€šé“åˆ†ä¸ºc1å’Œc2è¾“å…¥åˆ°ä¸¤ä¸ªåˆ†æ”¯ä¸­ï¼Œä½¿ç”¨concatæ›¿ä»£element-wise add
å †å blockçš„æ—¶å€™ï¼Œå¯ä»¥å°†concat, channel-shuffle, channel-splitåˆå¹¶ä¸ºä¸€ä¸ªelement-wiseæ“ä½œ
æ€æƒ³â€”<u>**ç‰¹å¾é‡ç”¨**</u>ï¼Œä¸Šå±‚çš„feature mapç›´æ¥ä¼ å…¥ä¹‹åçš„æ¨¡å—ï¼Œç›´æ¥æ˜ å°„ï¼ˆshufflenet v2å·¦ä¾§åˆ†æ”¯ï¼‰

- - - -

## SqueezeNet

> <u>**åˆ†å—è®¾è®¡**</u>æ€æƒ³ï¼Œæ¨¡å‹<u>**å‹ç¼©**</u>

1. ä½¿ç”¨`1x1`å·ç§¯ä»£æ›¿`3x3`å·ç§¯  
2. å‡å°‘`3x3`å·ç§¯è¾“å…¥é€šé“æ•°  
3. å»¶è¿Ÿä¸‹é‡‡æ ·ï¼Œå‰é¢layerè·å¾—æ›´å¤§ç‰¹å¾å›¾æå‡æ€§èƒ½  

**Fire Module**

ä¸¤å±‚å·ç§¯æ“ä½œï¼šsqueeze `1x1`, expand `1x1 + 3x3`
![](Figures/v2-5fde12f060519e493cb059484514f88a_hd.jpg)
ğŸ‘†ğŸ‘‡ <u>squeezeæ˜¯å•åˆ†æ”¯ï¼Œexpandæ˜¯äºŒåˆ†æ”¯</u>  
![](Figures/1DCBEDA4-1CA7-4029-8E78-BF80ABEF9898.png)
éƒ¨åˆ†3x3å˜æˆ1x1ï¼Œå‚æ•°æ•°é‡å‡å°‘ï¼Œä½†ä¸ºè·å¾—æ€§èƒ½éœ€è¦åŠ æ·±ç½‘ç»œæ·±åº¦ï¼ŒåŒæ—¶å¹¶è¡Œèƒ½åŠ›ä¸‹é™ï¼Œä¹Ÿå¯¼è‡´æµ‹è¯•æ—¶é—´å˜é•¿
![](Figures/v2-5f8ff8cb94babde05e69365336e77a62_hd.jpg)
ğŸ‘†ç½‘ç»œç»“æ„

- - - -

## Squeeze-and-Excitation Networks
[arXiv](https://www.arxiv.org/pdf/1709.01507.pdf)  
å·ç§¯æ ¸ï¼šç©ºé—´ç»´åº¦ä¿¡æ¯ï¼Œç‰¹å¾ç»´åº¦ä¿¡æ¯èšé›†  
ç©ºé—´spatialï¼šinception(multiscale)ï¼Œinside-outside(context)  
SENet->ç‰¹å¾ç»´åº¦,feature channel  
Motivation:
1. Explicitly model channel-interdependcies
2. Feature recalibration: enhance useful, suppress less useful

ç‰¹å¾é€šé“ä¹‹é—´çš„å…³ç³»ï¼šç‰¹å¾é‡æ ‡å®šï¼ˆé€šè¿‡å­¦ä¹ çš„æ–¹å¼æ¥è‡ªåŠ¨è·å–åˆ°æ¯ä¸ªç‰¹å¾é€šé“çš„é‡è¦ç¨‹åº¦ï¼Œç„¶åä¾ç…§è¿™ä¸ªé‡è¦ç¨‹åº¦å»æå‡æœ‰ç”¨çš„ç‰¹å¾å¹¶æŠ‘åˆ¶å¯¹å½“å‰ä»»åŠ¡ç”¨å¤„ä¸å¤§çš„ç‰¹å¾ï¼‰  
Squeeze: global pooling, é¡ºç€ç©ºé—´ç»´åº¦å‹ç¼©ï¼Œå¢åŠ å…¨å±€ç©ºé—´ä¿¡æ¯ï¼Œæ¯ä¸€ä¸ªäºŒç»´ç‰¹å¾å›¾å˜ä¸ºä¸€ä¸ªå®æ•°ã€‚è¡¨ç¤ºç‰¹å¾é€šé“ä¸Šå…¨å±€åˆ†å¸ƒï¼ŒåŠ ä¸ŠSæ¨¡å—ä½¿å¾—é è¿‘è¾“å…¥çš„å±‚ä¹Ÿå¯ä»¥è·å¾—å…¨å±€æ„Ÿå—é‡ Â 
Excitation: like gate in RNN. æ¯ä¸ªé€šé“ç”Ÿæˆæƒé‡ï¼Œå»ºæ¨¡ç›¸å…³æ€§ï¼Œcapture channel-wise dependencies Â 
Wçš„è¦æ±‚ * learn non-linear interaction * learn a non-mutually-exclusive relationship since we would like to ensure that multiple channels are allowed to be emphasised opposed to one-hot activation Â 
Reweight: multiply with feature map Â 

åµŒå…¥Inceptionï¼š  
åµŒå…¥ResNetï¼š additionä¹‹å‰è¿›è¡Œscaleæ“ä½œï¼Œé˜²æ¢¯åº¦å¼¥æ•£

---

## Hard Negative Mining in SSD & Focal Loss

1. Hard Negative Mining in SSD ä½œä¸ºä¸­é—´ç»“æœå¤„ç†çš„æ­¥éª¤ã€‚åªæœ‰GTæ¡†/å’ŒGTæ¡†IoUå¤§äºé˜ˆå€¼çš„æ‰æ˜¯æ­£æ ·æœ¬ï¼ˆå³æ­£ç¡®æ£€æµ‹æ¡†ï¼Œæ•°é‡å°‘ï¼‰ï¼Œå…¶ä»–éƒ½æ˜¯è´Ÿæ ·æœ¬ï¼ˆå³é”™è¯¯çš„æ£€æµ‹æ¡†ï¼Œæ•°é‡å¤§ï¼‰
   
   > <u>**ä¸ºäº†æ­£è´Ÿæ ·æœ¬æ•°é‡å¹³è¡¡**</u>ï¼Œé˜²æ­¢å°‘é‡å…³é”®çš„ï¼ˆæå‡æ€§èƒ½ï¼‰çš„è´Ÿæ ·æœ¬è¢«å¤§é‡æ­£æ ·æœ¬æ©ç›–è€Œæ— æ³•è¢«å­¦ä¹ /ä¼˜åŒ–åˆ°ã€‚   
   > è§£å†³é”™è¯¯æ ·ä¾‹å¤ªå¤šï¼Œ<u>**æ­£ç¡®æ ·ä¾‹å¤ªå°‘**</u>ï¼Œæ©ç›–æ­£ç¡®æ ·ä¾‹çš„é—®é¢˜ã€‚  
   
    **Hard Negative Mining in SSD**: ç›´æ¥é€šè¿‡æ ¹æ®ç½®ä¿¡åº¦æŸå¤±ï¼Œ<u>**æ’åºç­›é€‰**</u> æ¥é€‰æ‹©åˆ†ç±»æŸå¤±æœ€å¤§çš„è´Ÿæ ·æœ¬ï¼ˆå³ä¸æ˜¯ç‰©ä½“ä½†æ˜¯æœ‰æœ€é«˜çš„åˆ†ç±»ç½®ä¿¡åº¦ -> å›°éš¾åˆ†ç±»æ ·æœ¬_è¿·æƒ‘æ€§ï¼Œä¸¢å¼ƒä¸æ˜¯ç‰©ä½“ä½†åˆ†ç±»ç½®ä¿¡åº¦ç›¸å¯¹è¾ƒä½ -> ç®€å•_é”™è¯¯ä¸ä¸¥é‡/ä¸æ˜æ˜¾ï¼‰ï¼Œåªä¿ç•™åˆ†ç±»ç½®ä¿¡åº¦æŸå¤±è¾ƒå¤§çš„ï¼Œäººä¸ºä¿è¯æ ·æœ¬æ•°é‡å¹³è¡¡ã€‚

2. Focal Loss ç”¨äºæŸå¤±å‡½æ•°ä¸­
   
   > <u>**ä¸ºäº†èƒ½å­¦åˆ°å›°éš¾æ ·ä¾‹**</u>ï¼Œå­¦åˆ°æ›´å¤šï¼Œä¸è¢«ç®€å•æ©ç›–ã€‚  
   > è§£å†³é”™è¯¯æ ·ä¾‹ä¸­ï¼Œ<u>**ç®€å•çš„é”™è¯¯æ ·ä¾‹å¤ªå¤š**</u>ï¼Œå›°éš¾é”™è¯¯æ ·ä¾‹å¤ªå°‘ï¼Œä¸”æ±‚å’Œåæ©ç›–å›°éš¾çš„é”™è¯¯æ ·ä¾‹ï¼Œè€Œå¯¼è‡´æ£€æµ‹å™¨å­¦ä¸åˆ°å›°éš¾çš„é”™è¯¯æ ·ä¾‹ï¼ˆçœŸæ­£éœ€è¦å­¦/ä¼˜åŒ–çš„ï¼‰ã€‚  
   
    **Focal Loss**: é€šè¿‡ç»™ä¸åŒç½®ä¿¡åº¦çš„æ ·æœ¬<u>**å¢åŠ æƒé‡**</u>çš„æ–¹æ³•ã€‚æ¥è¿‘0/1ä¸ºç®€å•æ ·æœ¬ï¼Œæ¥è¿‘0.5ä¸ºéš¾æ ·æœ¬ã€‚æ‰€ä»¥æ­£ä¾‹x (1-p)ï¼Œè´Ÿä¾‹x pï¼Œä½¿ç”¨ _ä¸ç¡®å®šç¨‹åº¦_ ä½œä¸ºæƒé‡ã€‚éš¾æ˜“çš„é”™è¯¯éƒ½ä¼šå­¦ï¼Œä½†å›°éš¾çš„é”™è¯¯å¯¹losså½±å“æ›´å¤§ã€‚
    $L(p,y)=-(y\cdots (1-p)\cdots \log(p)+(1-y)\cdots p\cdots\log(1-p))$

---

## One-stage & Two-stage detector

#### RCNN
![](Figures/6F235DE5-4774-4527-9FC9-F8EAF8252AEE.png)


## ICCV 2019 workshop

#### LPIRC

https://rebootingcomputing.ieee.org/lpirc/2019
Winner talk:  [http://ieeetv.ieee.org/conference-highlights/award-winning-methods-for-lpirc-tao-sheng-lpirc-2018?rf=series|3](http://ieeetv.ieee.org/conference-highlights/award-winning-methods-for-lpirc-tao-sheng-lpirc-2018?rf=series%7C3) 
 [http://ieeetv.ieee.org/conference-highlights/deeper-neural-networks-kurt-keutzer-lpirc-2018?rf=series|3](http://ieeetv.ieee.org/conference-highlights/deeper-neural-networks-kurt-keutzer-lpirc-2018?rf=series%7C3) 
_Real Time Object Detection On Low Power Embedded Platforms_
_1810.01732.pdf_

#### Compact and Efficient Feature Representation and Learning

http://www.ee.oulu.fi/~lili/CEFRLatICCV2019.html
DCNN network quantization and compression, energy efficient network architectures, binary hashing techniques and data efficient techniques like meta learning

---

## Triplet Loss

![](Figures/20150707120209693.png)
ä¸‰å…ƒç»„: [anchor, positive, negative] æ‹‰è¿‘posï¼Œæ¨è¿œneg

$\mathcal{L}_{\mathrm{tri}}(\theta)=\sum_{a, p, n \atop y_{a}=y_{p} \neq y_{n}}\left[m+D_{a, p}-D_{a, n}\right]_{+}$

> é€‰å‡ºBä¸ªtripletsï¼Œåªç”¨äº†Bä¸ªè®­ç»ƒï¼Œå®é™…ä¸Šå¯ä»¥æœ‰`6B^2-4B`ç§tripletsçš„ç»„åˆï¼ˆ_Bä¸ªanchorï¼Œposå›ºå®šä¸€å¯¹ä¸€ï¼Œé™¤æ­¤äºŒå…¶ä»–æ‰€æœ‰éƒ½å¯ä»¥ä¸ºnegï¼Œ3B-2ç§ï¼›anchorå’Œposäº¤æ¢ä¹˜2_ï¼‰ `2*B*(3B-2)`ç§  

éš¾è®­ç»ƒï¼Œéœ€è¦**triplet mining**ã€‚åˆ†å‡ºhardï¼Œsemi-hardï¼Œeasyä¸‰ç§æ ·æœ¬
![](Figures/02_triplets.png)

1. <u>**Batch-Hard**</u>
   <u>é€‰æ‹©Pä¸ªç±»åˆ«ï¼ˆäººï¼‰ï¼Œæ¯ä¸ªç±»åˆ«Kä¸ªæ ·æœ¬ï¼ˆç…§ç‰‡ï¼‰ï¼ŒPKä¸ªæ ·æœ¬ä½œä¸ºanchor</u> ã€‚æ¯ä¸ªanchoråªé€‰æ‹©**è·ç¦»æœ€è¿œçš„poså’Œè·ç¦»æœ€è¿‘çš„neg**ï¼ˆæœ€hardï¼‰
   
   $\mathcal{L}_{\mathrm{BH}}(\theta ; X)=\overbrace{\sum_{i=1}^{P} \sum_{a=1}^{K}}^{\text {all anchors}} \left[m +  \overbrace{\max_{p=1 \ldots K} D\left( f_{\theta}\left(x_{a}^{i}\right), f_{\theta}(x_p^i)\right)}^{\text {hardest positive}} - \underbrace{\min\limits_{j=1 \ldots P,\; n=1\ldots K \atop j \neq i} D\left(f_{\theta}\left(x_{a}^{i}\right), f_{\theta}\left(x_{n}^{j}\right)\right)}_{\text {hardest negative}}\right]_{+} $
   ä¸€å…±$P_K$ä¸ªtriplets

2. <u>**Batch-All**</u>
   é€‰æ‹©Pä¸ªç±»åˆ«ï¼ˆäººï¼‰ï¼Œæ¯ä¸ªç±»åˆ«Kä¸ªæ ·æœ¬ï¼ˆç…§ç‰‡ï¼‰ï¼ŒPKä¸ªæ ·æœ¬ä½œä¸ºanchorï¼Œlossè®¡ç®—æ‰€æœ‰çš„poså’Œæ‰€æœ‰çš„negï¼ˆå’Œbaselineé€‰æ³•ç›¸åŒï¼‰
   
   $\mathcal{L}_{\mathrm{BA}}(\theta ; X)= \overbrace{\sum_{i=1}^{P} \sum_{a=1}^{K}}^{\text {all anchors}} \overbrace{\sum_{p=1 \atop p \neq a}^{K}}^{\text{all pos.}} \overbrace{\sum_{j=1 \atop j \neq i}^{P} \sum_{n=1}^{K}}^{\text {all neg.}}\left[m+d_{j, a, n}^{i, a, p}\right]_{+}$
   
   $d_{j, a, n}^{i, a, p}=D\left(f_{\theta}\left(x_{a}^{i}\right), f_{\theta}\left(x_{p}^{i}\right)\right)-D\left(f_{\theta}\left(x_{a}^{i}\right), f_{\theta}\left(x_{n}^{j}\right)\right)$
   $P_K$ä¸ªanchorï¼Œæ¯ä¸ªæœ‰$K-1$çš„posï¼Œ$P_K-K$ä¸ªnegï¼ˆå…¶ä»–æ‰€æœ‰ç±»åˆ«çš„æ ·æœ¬ï¼‰ã€‚ä¸€å…±$P_K(K-1)(P_K-K)$ä¸ªtriplets

---

## Long Short Term Memory (LSTM)

> Handling long-term dependencies

LSTM blocksğŸ‘‡

![image-20191018172300763](Figures/image-20191018172300763.png)

#### Core idea

![image-20191018172422527](Figures/image-20191018172422527.png)

ğŸ‘†**Cell state** convey information straight down along the entire chain

![img](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-gate.png)

ğŸ‘†**Gate** controls whether add/remove information to the cell state

---

![image-20191018174346388](Figures/image-20191018174346388.png)

ğŸ‘†**Forget Gate**: how many last state information($c_{t-1}$) keep/forget.

![image-20191018174812836](Figures/image-20191018174812836.png)

ğŸ‘†**Input Gate**: what new information weâ€™re going to store in the cell state.

Two parts: **sigmoid** layer decide which part of values we will update, **tanh** layer create a vector of new candidate values $\tilde{C}_t$

![image-20191018175359262](Figures/image-20191018175359262.png)

ğŸ‘†Apply to cell state: forget first, then partially add new candidate

![image-20191018175611169](Figures/image-20191018175611169.png)

ğŸ‘†**Output Gate**: decide what weâ€™re going to output

Two parts: **sigmoid** layer decide which parts of the cell state going to output, **tanh** layer filters cell state. **Multiply** them together to get final output.

---

#### Variants

**1. Peephole Connection**

gate layer look at the cell state

![image-20191018192328653](Figures/image-20191018192328653.png)

**2. Input&Forget Together**

make what to forget and what to add together. Only forget when going to input something, only input when we forget.

![image-20191018192633284](Figures/image-20191018192633284.png)

**3. Gated Recurrent Unit**

Combines the forget and input gated into "update gate". Merge the cell state and the hidden state.

![image-20191018192913785](Figures/image-20191018192913785.png)

[Reference](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)

---

## NASNet

> å…ˆåœ¨å°æ•°æ®é›†ä¸­è®­ç»ƒç½‘ç»œå•å…ƒï¼Œå†åœ¨å¤§æ•°æ®é›†ä¸­å †å å•å…ƒ  

å­¦ä¹ ç½‘ç»œä¸­å †å çš„ç½‘ç»œå•å…ƒ1. Normal cellå°ºå¯¸ä¸å˜ 2. Reduction cellå‡å°ºå¯¸
æ§åˆ¶å™¨ï¼šä¸€ç›´åœ¨æ‰§è¡Œä¸¤ä¸ªç‰¹å¾å›¾çš„<u>**èåˆ**</u>
![](Figures/v2-88f671125c2996924eb8a2c5b48c965d_r.jpg)
é€‰æ‹©ç¬¬ä¸€ä¸ªfeature mapå’Œç¬¬äºŒä¸ªfeature map(ç°è‰²) `2` ï¼Œè®¡ç®—è¾“å…¥çš„feature map A B(é»„è‰²) `2` ï¼Œé€‰æ‹©æ“ä½œèåˆä¸¤ä¸ªfeature map(ç»¿è‰²) `1` 
RNNé¢„æµ‹ï¼Œè¾“å‡º`2 x 5 x B`å…¶ä¸­ _normal cell_ + _reduction cell_ ï¼›æ¯ä¸ªéƒ½æœ‰Bä¸ªå—å †å ï¼›æ¯ä¸ªblockæœ‰äº”ä¸ªè¾“å‡ºğŸ‘†
NASNetè¿ç§»å­¦ä¹ ä¼˜åŒ–ç­–ç•¥ä¸ºProximal Policy Optimization(PPO) ğŸ‘ˆ 
æå‡º**scheduled drop path**ï¼Œéšæœºä¸¢å¼ƒéƒ¨åˆ†åˆ†æ”¯ï¼Œå¢åŠ ç½‘ç»œå†—ä½™overfittingï¼Œç±»ä¼¼ã€ŒInceptionã€
ä¸¢å¼ƒæ¦‚ç‡éšæ—¶é—´çº¿å‹å¢åŠ ï¼Œè®­ç»ƒæ¬¡æ•°å¤šå®¹æ˜“è¿‡æ‹Ÿåˆ

---

## DetNAS

**weight sharing** inherit its weights from supernet instead of training from scratch
**joint optimization** weight and architecture
**No proxy task or dataset** ä¸éœ€è¦æå‰è®­ç»ƒå°ç½‘ç»œ/å°æ¨¡å—ï¼Œä¹Ÿä¸éœ€è¦ä»å°æ•°æ®é›†åˆ°å¤§æ•°æ®é›†è®­ç»ƒ
**train from scratch** æ›´å¤šè¿­ä»£ï¼Œä¸é€‚ç”¨äºå°æ•°æ®é›†
é¦–å…ˆè®­ç»ƒ(pretrain+finetune)ä¸€ä¸ªsupernetï¼Œç„¶åå†supernetç©ºé—´ä¸­æ‰¾ï¼›ç›´æ¥åœ¨detä»»åŠ¡`Vdet`ä¸Šæœç´¢ <u>proxyless</u> ğŸ‘‡
![](Figures/DEEE8DD1-BD56-46A9-BA8A-6D16942C8049.png)
ä¼˜ç‚¹ï¼š

1. Decoupling: æ²¡æœ‰weightå’Œarchitectureä¹‹é—´çš„bias interaction

2. <u>supernetè®­å¥½åï¼Œç›´æ¥ç”¨valåœ¨supernetä¸Šæœç´¢</u> ç‰¹å®šåº”ç”¨åœºæ™¯çš„ç»“æ„ï¼Œè€Œä¸æ˜¯finetune

#### è®­ç»ƒsupernetğŸ‘‡

![](Figures/78DB7B34-1276-4AE0-AC78-0C38A7308692.png)

1. Single path sampling: ä½¿è®­ç»ƒå’Œæµ‹è¯•çš„é…ç½®ä¸€è‡´
   ![](Figures/74B60042-F0B7-48C0-BC3E-47E80BE0E4B0.png)

2. åŒæ­¥BN: <u>BN can not be frozen</u>, ä¸åŒpath BNçš„å‚æ•°ä¸åŒï¼ˆGroupNormé€Ÿåº¦æ…¢ï¼‰

#### æœç´¢å­ç½‘ç»“æ„

éå†æ¯ä¸ªpathï¼Œéœ€è¦é‡æ–°åœ¨trainsetä¸Šæœé›†è®¡ç®—BNçš„meanå’Œvar
ä¸ç”¨trainsetè®­ç»ƒå­ç½‘ï¼Œè€Œç›´æ¥åœ¨valsetä¸Ševal

#### Target task datasetä¸Šfinetuneå­ç½‘ç»“æ„

---

## Self-supervised Sample Mining

> <u>**semi-supervised**</u> <u>**weakly-supervised**</u> ä½¿ç”¨æœªæ ‡æ³¨çš„æ•°æ®æå‡æ¨¡å‹æ€§èƒ½   

![](Figures/image.png)
è¿™ä¸ªæ¡†æ¶æœ‰ä¸¤ä¸ªé˜¶æ®µï¼Œåˆ†åˆ«æ˜¯é€šè¿‡SSMå¯¹é«˜ä¸€è‡´æ€§æ ·æœ¬è¿›è¡Œä¼ªæ ‡æ³¨é˜¶æ®µå’Œé€šè¿‡ALé€‰æ‹©ä½ä¸€è‡´æ€§æ ·æœ¬é˜¶æ®µã€‚é¦–å…ˆä½¿ç”¨å·²æ ‡æ³¨çš„å›¾ç‰‡å¯¹æ¨¡å‹è¿›è¡Œfine-tuneï¼Œå¯¹æœªæ ‡æ³¨æˆ–éƒ¨åˆ†æ ‡æ³¨çš„å›¾ç‰‡æå–region proposalsï¼ˆæœªæ ‡æ³¨æ ·æœ¬ï¼‰ï¼ŒæŠŠè¿™äº› **region proposals <u>ç²˜è´´</u> åˆ°å·²æ ‡æ³¨çš„å›¾ç‰‡ä¸­è¿›è¡Œäº¤å‰å›¾ç‰‡éªŒè¯ï¼Œæ ¹æ®é‡æ–°é¢„æµ‹å‡ºæ¥çš„ç½®ä¿¡åº¦ç¡®å®šå¦‚ä½•å¯¹æœªæ ‡æ³¨æ ·æœ¬è¿›è¡Œæ ‡æ³¨** ã€‚å¯¹äºé«˜ä¸€è‡´æ€§æ ·æœ¬ï¼Œç›´æ¥è¿›è¡Œä¼ªæ ‡æ³¨ï¼Œå¯¹äºä½ä¸€è‡´æ€§æ ·æœ¬ï¼Œé€šè¿‡ALæŒ‘é€‰å‡ºæ¥ï¼Œè®©ç›¸å…³äººå‘˜è¿›è¡Œæ ‡æ³¨ã€‚ä¼ªæ ‡æ³¨çš„æ ·æœ¬ç”¨äºæ¨¡å‹çš„fine-tuneï¼Œè€Œæ–°æ ‡æ³¨çš„æ ·æœ¬æ·»åŠ åˆ°å·²æ ‡æ³¨çš„å›¾ç‰‡ä¸­ï¼ŒåŒæ—¶ä¹Ÿç”¨äºæ¨¡å‹çš„fine-tune  
å¯¹äºå¥½çš„æ ·æœ¬`xi`ï¼Œproposalä¸­çš„å†…å®¹å¯ä»¥å¾ˆå¥½çš„å±•ç¤ºjç±»çš„ç‰¹å¾ï¼Œç²˜è´´åˆ°æ²¡æœ‰jç±»çš„å›¾ç‰‡ä¸­ï¼Œæ–°ç”Ÿæˆçš„å›¾ç‰‡ä¸­çš„proposalæœ‰åŒ…å«`xi`çš„proposalï¼Œä¸”å…·æœ‰å¾ˆå¤§çš„æ¦‚ç‡å€¼ï¼Œ<u>**é«˜ä¸€è‡´æ€§**</u>è®¤ä¸ºä¹‹å‰çš„æ ·æœ¬æ¡†å‡†ç¡®æ— é”™è¯¯â¡ï¸æ­£æ ·æœ¬
ä»»åŠ¡åˆ†ç±»ğŸ‘‡
![](Figures/image%202.png)

---

## Bi-box Regression for Pedestrian Detection and Occlusion Estimation

> Part detectorï¼Œé’ˆå¯¹è¡Œäººé®æŒ¡é—®é¢˜ï¼Œå›å½’ã€Œå…¨èº«ã€+ã€Œå¯è§ã€ä¸¤ä¸ªæ¡†  

![](Figures/97B54C4E-F68D-4AB8-B030-A7C87315CE3E.png)
äºŒåˆ†æ”¯ç½‘ç»œï¼š

1. **Full body estimation** åªå¯¹pos proposalå›å½’
2. **Visible part estimation** å¯¹poså’Œnegçš„proposalå›å½’ï¼ˆFG&BGï¼‰ï¼Œ <u>neg proposalå›å½’ç¼©å°åŒºåŸŸ $\to$ 0</u>
   pos/neg proposalæ ¹æ®å’Œæ ‡æ³¨(full-body)çš„IoUå†³å®š
   ![](Figures/AFA72E30-3E28-4167-8CC3-28C74B49AA10.png)
   ğŸ‘†proposalç”±RPNè·å¾—ï¼Œsoftmax1å’Œsoftmax2é¢„æµ‹è¡Œäººå¾—åˆ†ã€‚ <u>fuse</u> æ—¶ï¼Œä¸¤ä¸ªéƒ½ä¸ºposï¼Œè¾“å‡ºpæ›´é«˜ï¼›ä¸€ä¸ªä¸ºnegï¼Œå¦ä¸€åˆ†æ”¯posï¼Œåˆ™posåˆ†æ”¯å¢åŠ p

#### Training

æ ·æœ¬æ ‡æ³¨ä¸¤ä¸ªæ¡†ã€‚æŠŠäº§ç”Ÿçš„proposal`P={x,y,w,h}`å’Œæ ‡æ³¨æ¡†`Q=(Full,Vis)`matchï¼Œpos-proposalè§„åˆ™ä¸º`IoU(P,F)>thresh_1` && `C(P,V)>thresh_2`. Cå®šä¹‰ä¸ºğŸ‘‡$C(P,\bar{V})=\frac{\text {Area}(P\cap\bar{V})}{\text {Area}(\bar{V})}$

è®­ç»ƒæ ·æœ¬`X=(Img, P, cate=1, F, V)`ï¼Œregression targetä¸ºğŸ‘‡
$\bar{f}^x=\frac{\bar{F}^x-P^x}{P^W},\;\bar{f}^y=\frac{\bar{F}^y-P^y}{P^h}$

$\bar{f}^w=\log(\frac{\bar{F}^w}{P^w}),\;\bar{f}^h=\log(\frac{\bar{F}^h}{P^h})$

Neg-proposal=1.background   2.poorly aligned proposal   å›å½’w,h -> 0

> Why should force _visible part of neg-proposal_ shrink? ã€Œvisåˆ†æ”¯å¯¹poså’Œnegéƒ½å¤„ç†ã€ #æ²¡æ‡‚  
> If the visible part estimation branch is trained to only regress visible parts for positive pedestrian proposals, the training of this branch would be dominated by pedestrian examples which are non-occluded or slightly occluded. For these pedestrian proposals, their ground-truth visible part and full body regions overlap largely. As a result, the estimated visible part region of a negative pedestrian proposal is often close to its estimated full body re- gion and the difference between the two branches after training would not be as large as the case in which the visible part regions of negative examples are forced to shrink to their centers.  

ä¸å¯¹è´Ÿæ ·æœ¬å¤„ç†ï¼Œåˆ™å¯¹è´Ÿæ ·æœ¬çš„é¢„æµ‹ç»“æœä¸¤ä¸ªåˆ†æ”¯ç›¸åŒã€Œfullåˆ†æ”¯å¯¹æ‰€æœ‰æ ·æœ¬å›å½’åˆ°GTï¼Œvisåˆ†æ”¯å¯¹æ­£æ ·æœ¬å›å½’åˆ°GTï¼Œå¯¹è´Ÿæ ·æœ¬å›å½’åˆ°0ã€
![](Figures/D29D7BC4-9682-4E65-AB16-3A92A974DD47.png)
ğŸ‘†è“è‰²æ¡†ï¼Œå’Œfull(GT)é‡åˆåº¦é«˜ï¼Œä½†å’Œvisé‡åˆåº¦ä½ã€‚åœ¨Faster-RCNNä¸­è¢«è®¤ä¸ºposï¼Œåœ¨æœ¬æ–‡ä¸­è®¤ä¸ºnegã€‚æ›´å¼ºçš„è¯„ä»·æ ‡å‡†

---

## Precision Gating: Improving Neural Network Efficiency with Dynamic Dual-Precision Activations

<u>**ç½‘ç»œé‡åŒ–**</u>
Network compression: sparsity, quantization, and binarization
ä½¿ç”¨ä½ç²¾åº¦çš„æµ®ç‚¹è¿ç®—ï¼Œç›¸æ¯”äºé™æ€ç¡®å®šæ¯ä¸ªweightå’Œactivationçš„ç²¾åº¦ï¼Œæœ¬æ–‡**æ ¹æ®ç½‘ç»œè¾“å…¥**(ä¾‹å¦‚èƒŒæ™¯ä¸éœ€è¦ç²¾ç¡®è®¡ç®—)åŠ¨æ€ç¡®å®š **Tuning the bit width per layer**

#### Precision Gating

> Computes most features with low-precision arithmetic ops and only updates few important features to a high-precision  

1. å¯¹äºæ‰€æœ‰å±‚ä½ç²¾åº¦è®¡ç®—
2. å¯¹äºè¾“å‡ºçš„feature mapä¸­è¾ƒå¤§å€¼è®¤ä¸ºé‡è¦ç‰¹å¾ï¼Œå¯¹å…¶è¿›è¡Œç¨€ç–æ›´æ–°ï¼Œæé«˜ç²¾åº¦(sparse back propagation)

ç”¨åœ¨shufflenet v2ä¸Šæå‡26% ImageNetåˆ†ç±»ç²¾åº¦

---

## Repulsion Loss: Detecting Pedestrians in a crowd

> ReIdçš„occludeé—®é¢˜ï¼Œä½¿ä¸åŒç›®æ ‡çš„æ£€æµ‹æ¡†è¿œç¦»ã€Œç±»ä¼¼triplet lossã€  

![](Figures/%E6%88%AA%E5%B1%8F2020-02-23%E4%B8%8A%E5%8D%8812.28.04.png)

$L=L_{Attr}+\alpha*L_{RepGT}+\beta*L_{RepBox}$

#### Attraction term

é‡‡ç”¨æ£€æµ‹æ¡†æ¶ä¸­bboxå›å½’loss

$L_{\mathrm{Attr}}=\frac{\sum_{P \in \mathcal{P}_{+}} \operatorname{Smooth}_{L 1}\left(P, G_{A t t r}^{P}\right)}{\left|\mathcal{P}_{+}\right|}$

#### Repulsion Term (RepGT)

å’Œå‘¨å›´GTç›®æ ‡æ¡†è¿œç¦»ï¼Œè¿œç¦»IoUå¤§ä¸”æ²¡æœ‰åŒ¹é…çš„ç›®æ ‡æ¡†
å³$G_{R e p}^{P}=\underset{G \in \mathcal{G} \backslash\left\{G_{A t r}^{P}\right\}}{\arg \max } \operatorname{IoU}(G, P)$

ç±»ä¼¼IoU lossï¼ˆä¸æ˜¯IoUè€Œæ˜¯IoGï¼šè‹¥æœ€å°åŒ–IoUï¼Œåˆ™é¢„æµ‹æ¡†è¶Šå¤§IoUè¶Šå°ï¼‰

$\operatorname{IoG}(P,G) \overset{\triangle}{=}\frac{area(P\cap G)}{area(G)}$

$L_{\mathrm{RepGT}}=\frac{\sum_{P \in \mathcal{P}_{+}} \operatorname{Smooth}_{ln}\left(\operatorname{IoG}(P, G_{Rep}^{P})\right)}{\left|\mathcal{P}_{+}\right|}$

where

$\operatorname{smooth}_{l n}=\left\{\begin{array}{ll}
{-\ln (1-x)} & {x \leq \sigma} \\
{\frac{x-\sigma}{1-\sigma}-\ln (1-\sigma)} & {x>\sigma}
\end{array}\right.$
ä½¿é¢„æµ‹æ¡†é›†ä¸­åœ¨åŒ¹é…çš„ç›®æ ‡é™„è¿‘ï¼Œè€Œä¸ä¼šåç§»åˆ°ä¸´è¿‘ç‰©ä½“

#### Repulsion Term (RepBox)

é¢„æµ‹æ¡†å’Œå…¶ä»–é¢„æµ‹æ¡†è¿œç¦»ï¼ˆåŒ¹é…ä¸Šä¸åŒç‰©ä½“çš„ç›®æ ‡æ¡†ï¼‰
$L_{\mathrm{RepBox}}=\frac{\sum_{i \neq j} \operatorname{Smooth}_{l n}\left(\operatorname{IoU}\left(B^{P_{i}}, B^{P_{j}}\right)\right)}{\sum_{i \neq j} \mathbb{1}\left[\operatorname{IoU}\left(B^{P_{i}}, B^{P_{j}}\right)>0\right]+\epsilon}$

é˜²æ­¢ä¸åŒç‰©ä½“çš„ä¸¤ä¸ªæ£€æµ‹æ¡†è¢«NMSè¿‡æ»¤æ‰

---

## Normalization

![](Figures/2020-02-24-16-07-43-image.png)

#### Training

Batch Normå¯¹ä¸€ä¸ªbatchä¸­æ‰€æœ‰æ ·æœ¬çš„åŒä¸€channelè®¡ç®—ç»Ÿè®¡é‡ï¼Œå—batch_sizeå½±å“

Layer Normå¯¹å•ä¸ªæ ·æœ¬è®¡ç®—ç»Ÿè®¡é‡ï¼Œç”¨äºRNN

Instance Normå•æ ·æœ¬å•é€šé“è®¡ç®—ï¼Œé£æ ¼è¿ç§»

Group Normå¯¹é€šé“åˆ†ç»„ï¼Œè§£å†³BNä¾èµ–batch_sizeçš„é—®é¢˜

Switchable Normalizationè®¡ç®—BNã€LNã€INä¸‰ç§çš„ç»Ÿè®¡é‡ï¼Œç„¶ååŠ æƒ$w_k$ä½œä¸ºSNçš„å‡å€¼$\mu$å’Œæ–¹å·®$\sigma$ã€Œè§£å†³batch_sizeå½±å“ï¼Œè‡ªé€‚åº”ä¸åŒä»»åŠ¡ã€

normğŸ‘‡

$\hat{h}_{n c i j}=\gamma \frac{h_{n c i j}-\Sigma_{k \in \Omega} w_{k} \mu_{k}}{\sqrt{\Sigma_{k \in \Omega} w_{k}^{\prime} \sigma_{k}^{2}+\epsilon}}+\beta$

åŠ æƒæƒé‡å½’ä¸€åŒ–ğŸ‘‡

$w_k=\frac{e^{\lambda_k}}{\sum_{z\in\{\text {bn,ln,in}\}}e^{\lambda_z}}$

![](Figures/2020-02-24-16-22-39-image.png)

#### Testing

LN, INæ­£å¸¸è®¡ç®—ï¼ŒBNé‡‡ç”¨<u>batch average</u>æ–¹å¼ï¼Œå…·ä½“è¿‡ç¨‹æ˜¯ï¼Œå†»ç»“æ‰€æœ‰çš„å‚æ•°ï¼Œä»è®­ç»ƒé›†ä¸­éšæœºæŠ½å–ä¸€å®šæ•°é‡çš„æ ·æœ¬ï¼Œè®¡ç®—SNçš„å‡å€¼å’Œæ–¹å·®ï¼Œç„¶åä½¿ç”¨ä»–ä»¬çš„å¹³å‡å€¼ä½œä¸ºBNçš„ç»Ÿè®¡å€¼

Ref: [https://zhuanlan.zhihu.com/p/39296570](https://zhuanlan.zhihu.com/p/39296570)

---

## Universal-RCNN: Universal Object Detection via Transferable Graph R-CNN

> è§£å†³æ£€æµ‹åŸŸè¿ç§»ï¼Œä¸åŒåŸŸ<u>**ç±»åˆ«**</u>å…³ç³»æ¨ç†()reasoning)å’Œè¿ç§»(transfer)

**Intra-Domain Reasoning**: åŸŸå†…éƒ¨å›¾è¡¨ç¤ºä¸Šä¼ æ’­ï¼Œç±»åˆ«ä¹‹é—´ç›¸å…³æ€§

**Inter-Graph Transfer**: åŸŸé—´è¿ç§»ï¼Œä¸åŒåŸŸç±»åˆ«ä¹‹é—´å±‚æ¬¡å…³ç³»

![](Figures/2020-02-25-20-41-49-image.png)

#### Intra-Domain Reasoning Module

1. ä½¿ç”¨backboneè®¡ç®—proposal feature (global **semantic pool**)

2. æ„å»º**åŒºåŸŸ**å…³ç³»å›¾$G_{T\to T}$ï¼ŒèŠ‚ç‚¹è¡¨ç¤ºregion proposalï¼Œè¾¹è¡¨ç¤ºå…³ç³»ã€‚proposalä¹‹é—´å…³è”å…³ç³»(attribute similarities, interactions)

3. å­¦ä¹ è¾¹æƒé‡$\mathbf{Z}\mathbf{Z}^T$ï¼Œåªä¿ç•™é‡è¦proposalå…³ç³»çš„**ç¨€ç–é‚»æ¥çŸ©é˜µ**

4. propsoal featureåœ¨GCNè®¡ç®—ï¼Œå’ŒåŸå§‹ç‰¹å¾concatï¼Œå¾—åˆ°æ–°çš„global semantic pool $\mathbf{P_S}$

sharing common features between categories via connected edges such as similar attributes & relations.

improve feature rep. by adding adaptive contexts from global semantic pool

#### Inter-Domain Transfer Module

> bridge the gap between domains

æºåŸŸç”¨ä¸Šè¿°æ¨¡å—æ„å»º$\mathbf{P_S}$ï¼Œæ„å»º$\mathbf{G_{S\to T}}$ï¼ŒGCNè®¡ç®—ä»æºåŸŸåˆ°ç›®æ ‡åŸŸè¿ç§»ï¼ŒconcatæºåŸŸç‰¹å¾

![](Figures/2020-02-25-22-03-19-image.png)
